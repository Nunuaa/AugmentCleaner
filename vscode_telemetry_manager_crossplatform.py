#!/usr/bin/env python3
"""
VS Code/Cursor/VSCodium Telemetry Manager (è·¨å¹³å°ç‰ˆ) - ä¼˜åŒ–ç‰ˆ
ä¿®æ”¹é¥æµ‹IDå’Œæ¸…ç†æ•°æ®åº“å·¥å…·
æ”¯æŒ Windows/macOS/Linux ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹

ä¼˜åŒ–ç‰¹æ€§:
- é…ç½®æ–‡ä»¶æ”¯æŒ (telemetry_config.json)
- å¹¶å‘å¤„ç†æå‡æ€§èƒ½
- æ›´ç²¾ç¡®çš„Augmentå¯¹è¯æ•°æ®æ¸…ç†
- æƒé™æ£€æŸ¥å’Œå®‰å…¨éªŒè¯
"""
import json
import sqlite3
import uuid
import shutil
import subprocess
import glob
import logging
import re
import time
import sys
import platform
import os
from pathlib import Path
from typing import Dict, List, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

# å°è¯•å¯¼å…¥psutilï¼Œå¦‚æœæ²¡æœ‰å®‰è£…åˆ™ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False
    logging.warning("psutilæœªå®‰è£…ï¼Œå°†ä½¿ç”¨åŸºæœ¬çš„è¿›ç¨‹ç®¡ç†åŠŸèƒ½")

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TelemetryManager:
    """VS Codeç³»åˆ—ç¼–è¾‘å™¨çš„é¥æµ‹ç®¡ç†å™¨ (è·¨å¹³å°) - ä¼˜åŒ–ç‰ˆ"""

    # æ”¯æŒçš„ç¼–è¾‘å™¨é…ç½® - æ‰©å±•ç‰ˆï¼ˆæ”¯æŒæ‰€æœ‰VSCodeç³»åˆ—ï¼‰
    EDITORS = {
        # ä¸»æµç¼–è¾‘å™¨
        'vscode': 'Code',
        'cursor': 'Cursor',
        'windsurf': 'Windsurf',
        'vscodium': 'VSCodium',

        # VS Codeå˜ä½“
        'code-oss': 'Code - OSS',
        'vscode-insiders': 'Code - Insiders',
        'vscode-exploration': 'Code - Exploration',

        # AIç¼–è¾‘å™¨
        'codebuddy': 'CodeBuddy',
        'kiro': 'Kiro',
        'trae': 'Trae',
        'qoder': 'Qoder',

        # å…¶ä»–åŸºäºVSCodeçš„ç¼–è¾‘å™¨
        'theia': 'Theia',
        'openvscode': 'OpenVSCode',
        'gitpod': 'Gitpod',
        'code-server': 'code-server',
        'stackblitz': 'StackBlitz',

        # ä¼ä¸šç‰ˆ
        'vscode-server': 'VS Code Server',
        'github-codespaces': 'GitHub Codespaces'
    }

    def __init__(self, config_path: Optional[str] = None):
        self.home_path = Path.home()
        self.current_os = platform.system().lower()
        self.app_support_path = self._get_app_support_path()

        # åŠ è½½é…ç½®æ–‡ä»¶
        self.config = self._load_config(config_path)

        print(f"ğŸ–¥ï¸  æ£€æµ‹åˆ°ç³»ç»Ÿ: {self.current_os.title()}")
        print(f"ğŸ“ é…ç½®è·¯å¾„: {self.app_support_path}")
        print(f"âš™ï¸  é…ç½®ç‰ˆæœ¬: {self.config.get('version', 'N/A')}")

    def _load_config(self, config_path: Optional[str] = None) -> Dict:
        """åŠ è½½é…ç½® - é»˜è®¤ä½¿ç”¨å†…ç½®é…ç½®ï¼Œå¯é€‰å¤–éƒ¨é…ç½®æ–‡ä»¶"""
        # å…ˆè·å–å†…ç½®é…ç½®
        config = self._get_default_config()

        # å¦‚æœæä¾›äº†å¤–éƒ¨é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œå°è¯•åŠ è½½å¹¶åˆå¹¶
        if config_path is not None:
            config_path = Path(config_path)
            if config_path.exists():
                try:
                    with open(config_path, 'r', encoding='utf-8') as f:
                        user_config = json.load(f)

                    # æ·±åº¦åˆå¹¶é…ç½®
                    for key, value in user_config.items():
                        if isinstance(value, dict) and key in config:
                            config[key].update(value)
                        else:
                            config[key] = value

                    logger.info(f"âœ… å·²åŠ è½½å¤–éƒ¨é…ç½®: {config_path}")
                except Exception as e:
                    logger.warning(f"âš ï¸  åŠ è½½å¤–éƒ¨é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨å†…ç½®é…ç½®")

        return config

    def _get_default_config(self) -> Dict:
        """è·å–å†…ç½®é…ç½® - å…¨é›†æˆï¼Œæ— éœ€å¤–éƒ¨æ–‡ä»¶"""
        return {
            "version": "3.0",

            # Augmentæ‰©å±•IDåˆ—è¡¨ï¼ˆæ”¯æŒæ‰€æœ‰VSCodeç³»åˆ—ç¼–è¾‘å™¨ï¼‰
            "augment_extension_ids": [
                "augmentcode.augment",
                "augmentcode.augment-vscode",
                "augmentcode.augment-cursor",
                "augmentcode.augment-windsurf",
                "augmentcode.augment-vscodium",
                "augment.augment",
                "vscode-augment",
                "augment-code",
                "augmentcode.vscode-augment"
            ],

            # AIæ‰©å±•IDåˆ—è¡¨ï¼ˆå¯é€‰æ¸…ç†ï¼‰
            "ai_extension_ids": [
                "github.copilot",
                "github.copilot-chat",
                "tabnine.tabnine-vscode",
                "codeium.codeium",
                "continue.continue",
                "amazonwebservices.aws-toolkit-vscode",
                "cursor.cursor-vscode"
            ],

            # æ•°æ®åº“æ¸…ç†å…³é”®è¯
            "database_cleanup_keys": {
                "augment_specific": [
                    "%augment%", "%AugmentCode%", "%augmentcode%",
                    "%chat%", "%conversation%", "%message%",
                    "%dialog%", "%session%", "%history%",
                    "%Fix with Augment%", "%vscode-augment%"
                ],
                "chat": [
                    "%chat%", "%conversation%", "%message%", "%dialog%",
                    "%session%", "%history%", "%augment%", "%AugmentCode%",
                    "%augmentcode%", "%vscode-augment%", "%Fix with Augment%"
                ],
                "analytics": [
                    "%telemetry%", "%tracking%", "%analytics%", "%metrics%"
                ]
            },

            # å±é™©è·¯å¾„ï¼ˆé˜²æ­¢è¯¯åˆ ï¼‰
            "dangerous_paths": [
                "C:\\Windows", "C:\\Program Files", "C:\\Program Files (x86)",
                "/System", "/Library", "/usr", "/bin", "/sbin",
                str(Path.home()),
                str(Path.home() / "Desktop"),
                str(Path.home() / "Documents"),
                str(Path.home() / "Downloads")
            ],

            # æ€§èƒ½é…ç½®
            "performance": {
                "enable_parallel_processing": True,
                "max_workers": 4,
                "scan_timeout": 300,  # æ‰«æè¶…æ—¶ï¼ˆç§’ï¼‰
                "clean_timeout": 600  # æ¸…ç†è¶…æ—¶ï¼ˆç§’ï¼‰
            },

            # æ£€æµ‹é…ç½®
            "detection": {
                "enable_auto_scan": True,  # å¯ç”¨è‡ªåŠ¨æ‰«æ
                "enable_windows_programs_scan": True,  # Windows Programsç›®å½•æ‰«æ
                "known_editors_only": False  # ä»…æ£€æµ‹å·²çŸ¥ç¼–è¾‘å™¨
            },

            # æ¸…ç†é…ç½®
            "cleanup": {
                "backup_before_clean": True,  # æ¸…ç†å‰å¤‡ä»½
                "verify_after_clean": True,   # æ¸…ç†åéªŒè¯
                "max_retries": 3,             # æœ€å¤§é‡è¯•æ¬¡æ•°
                "retry_delay": 2              # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
            }
        }
    
    def _get_app_support_path(self) -> Path:
        """æ ¹æ®æ“ä½œç³»ç»Ÿè·å–åº”ç”¨æ”¯æŒè·¯å¾„"""
        if self.current_os == 'windows':
            # Windows: %APPDATA%
            return Path(os.environ.get('APPDATA', self.home_path / 'AppData' / 'Roaming'))
        elif self.current_os == 'darwin':
            # macOS: ~/Library/Application Support
            return self.home_path / "Library" / "Application Support"
        else:
            # Linux: ~/.config
            return self.home_path / ".config"
        
    def get_editor_path(self, editor_type: str) -> Path:
        """è·å–ç¼–è¾‘å™¨çš„é…ç½®è·¯å¾„"""
        if editor_type not in self.EDITORS:
            raise ValueError(f"ä¸æ”¯æŒçš„ç¼–è¾‘å™¨ç±»å‹: {editor_type}")
        
        return self.app_support_path / self.EDITORS[editor_type]
    
    def get_system_info(self) -> Dict:
        """è·å–ç³»ç»Ÿä¿¡æ¯ - å¢å¼ºç‰ˆï¼Œè‡ªåŠ¨æ£€æµ‹æ‰€æœ‰VSCodeç³»åˆ—ç¼–è¾‘å™¨"""
        info = {
            'platform': self.current_os,
            'platform_version': platform.platform(),
            'python_version': platform.python_version(),
            'home_path': str(self.home_path),
            'app_support_path': str(self.app_support_path),
            'available_editors': []
        }

        print("\nğŸ” æ­£åœ¨æ‰«æå·²å®‰è£…çš„VSCodeç³»åˆ—ç¼–è¾‘å™¨...")

        # æ–¹æ³•1: æ£€æµ‹å·²çŸ¥ç¼–è¾‘å™¨
        for editor_key, editor_name in self.EDITORS.items():
            editor_path = self.get_editor_path(editor_key)
            if editor_path.exists():
                # æ£€æŸ¥æ˜¯å¦çœŸçš„æ˜¯ç¼–è¾‘å™¨ç›®å½•ï¼ˆåŒ…å«Userç›®å½•ï¼‰
                user_dir = editor_path / "User"
                if user_dir.exists():
                    info['available_editors'].append({
                        'type': editor_key,
                        'name': editor_name,
                        'path': str(editor_path),
                        'detection_method': 'known_editor'
                    })
                    print(f"   âœ… æ‰¾åˆ°: {editor_name} ({editor_key})")

        # æ–¹æ³•2: è‡ªåŠ¨æ‰«æapp_support_pathä¸‹çš„æ‰€æœ‰å¯èƒ½çš„ç¼–è¾‘å™¨
        print("\nğŸ” æ‰«ææœªçŸ¥çš„VSCodeç³»åˆ—ç¼–è¾‘å™¨...")
        if self.app_support_path.exists():
            for item in self.app_support_path.iterdir():
                if item.is_dir():
                    # æ£€æŸ¥æ˜¯å¦æ˜¯VSCodeç³»åˆ—ç¼–è¾‘å™¨çš„ç‰¹å¾
                    user_dir = item / "User"
                    global_storage = item / "User" / "globalStorage"

                    # ç‰¹å¾æ£€æµ‹ï¼šæœ‰Userç›®å½•å’ŒglobalStorage
                    if user_dir.exists() and global_storage.exists():
                        # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨å·²çŸ¥åˆ—è¡¨ä¸­
                        already_detected = any(
                            e['path'] == str(item)
                            for e in info['available_editors']
                        )

                        if not already_detected:
                            # å°è¯•è¯†åˆ«ç¼–è¾‘å™¨ç±»å‹
                            editor_name = item.name
                            editor_key = editor_name.lower().replace(' ', '-')

                            info['available_editors'].append({
                                'type': editor_key,
                                'name': editor_name,
                                'path': str(item),
                                'detection_method': 'auto_scan'
                            })
                            print(f"   ğŸ†• å‘ç°æœªçŸ¥ç¼–è¾‘å™¨: {editor_name}")

        # æ–¹æ³•3: æ£€æŸ¥å¸¸è§çš„å®‰è£…ä½ç½®ï¼ˆWindowsç‰¹æ®Šå¤„ç†ï¼‰
        if self.current_os == 'windows':
            print("\nğŸ” æ£€æŸ¥Windowsç‰¹æ®Šå®‰è£…ä½ç½®...")
            local_appdata = Path(os.environ.get('LOCALAPPDATA', ''))
            if local_appdata.exists():
                # æ£€æŸ¥Programsç›®å½•
                programs_dir = local_appdata / "Programs"
                if programs_dir.exists():
                    for item in programs_dir.iterdir():
                        if item.is_dir():
                            # æ£€æŸ¥æ˜¯å¦æœ‰VSCodeç‰¹å¾
                            possible_data_dirs = [
                                self.app_support_path / item.name,
                                self.app_support_path / item.name.replace(' ', '')
                            ]

                            for data_dir in possible_data_dirs:
                                if data_dir.exists() and (data_dir / "User").exists():
                                    already_detected = any(
                                        e['path'] == str(data_dir)
                                        for e in info['available_editors']
                                    )

                                    if not already_detected:
                                        editor_name = item.name
                                        editor_key = editor_name.lower().replace(' ', '-')

                                        info['available_editors'].append({
                                            'type': editor_key,
                                            'name': editor_name,
                                            'path': str(data_dir),
                                            'detection_method': 'windows_programs'
                                        })
                                        print(f"   ğŸ†• å‘ç°: {editor_name} (Programsç›®å½•)")

        print(f"\nâœ… å…±æ£€æµ‹åˆ° {len(info['available_editors'])} ä¸ªç¼–è¾‘å™¨")

        return info
    
    def kill_editor_processes(self, editor_type: str) -> bool:
        """å¼ºåˆ¶ç»“æŸç¼–è¾‘å™¨è¿›ç¨‹ (è·¨å¹³å°)"""
        try:
            editor_name = self.EDITORS[editor_type]
            
            if self.current_os == 'windows':
                # Windows: ä½¿ç”¨taskkillå¼ºåˆ¶æ€æ­»
                result = subprocess.run(
                    ['taskkill', '/F', '/IM', f'{editor_name}.exe'],
                    capture_output=True, 
                    text=True
                )
            elif self.current_os == 'darwin':
                # macOS: ä½¿ç”¨killall -9å¼ºåˆ¶æ€æ­»
                result = subprocess.run(
                    ['killall', '-9', editor_name], 
                    capture_output=True, 
                    text=True
                )
            else:
                # Linux: ä½¿ç”¨pkill -9å¼ºåˆ¶æ€æ­»
                result = subprocess.run(
                    ['pkill', '-9', '-f', editor_name], 
                    capture_output=True, 
                    text=True
                )
                
            logger.info(f"å°è¯•ç»“æŸ {editor_name} è¿›ç¨‹ ({self.current_os}): {result.returncode}")
            return True
        except Exception as e:
            logger.error(f"ç»“æŸè¿›ç¨‹æ—¶å‡ºé”™: {e}")
            return False
    
    def kill_editor_processes_command(self, editor_type: str) -> Dict:
        """å®Œæ•´çš„è¿›ç¨‹ç®¡ç†å‘½ä»¤ - å¸¦ç­‰å¾…å’ŒçŠ¶æ€æ£€æŸ¥"""
        
        logger.info(f"å¼€å§‹å®Œæ•´è¿›ç¨‹ç»ˆæ­¢æµç¨‹: {editor_type}")
        
        if not HAS_PSUTIL:
            # å¦‚æœæ²¡æœ‰psutilï¼Œå›é€€åˆ°åŸºæœ¬çš„è¿›ç¨‹ç®¡ç†
            logger.warning("psutilä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºæœ¬è¿›ç¨‹ç®¡ç†")
            basic_result = self.kill_editor_processes(editor_type)
            return {
                'editor_type': editor_type,
                'status': 'success' if basic_result else 'error',
                'message': 'ä½¿ç”¨åŸºæœ¬è¿›ç¨‹ç®¡ç†åŠŸèƒ½',
                'killed_processes': [],
                'remaining_processes': [],
                'fallback_used': True
            }
        
        editor_info = {
            'vscode': {
                'app_names': ['Visual Studio Code', 'Code'],
                'process_names': ['code', 'Code Helper']
            },
            'cursor': {
                'app_names': ['Cursor'],
                'process_names': ['cursor', 'Cursor Helper']
            },
            'vscodium': {
                'app_names': ['VSCodium'],
                'process_names': ['codium', 'VSCodium Helper']
            },
            'code-oss': {
                'app_names': ['Code - OSS'],
                'process_names': ['code-oss', 'code-oss Helper']
            },
            'vscode-insiders': {
                'app_names': ['Visual Studio Code - Insiders'],
                'process_names': ['code-insiders', 'code-insiders Helper']
            },
            'theia': {
                'app_names': ['Theia'],
                'process_names': ['theia', 'node']
            },
            'openvscode': {
                'app_names': ['OpenVSCode Server'],
                'process_names': ['openvscode-server', 'node']
            },
            'gitpod': {
                'app_names': ['Gitpod'],
                'process_names': ['gitpod', 'node']
            }
        }
        
        if editor_type not in editor_info:
            return {
                'editor_type': editor_type,
                'status': 'error',
                'error': f'ä¸æ”¯æŒçš„ç¼–è¾‘å™¨ç±»å‹: {editor_type}'
            }
        
        info = editor_info[editor_type]
        killed_processes = []
        remaining_processes = []
        
        try:
            # ç¬¬1æ­¥: æŸ¥æ‰¾è¿è¡Œä¸­çš„è¿›ç¨‹
            logger.info("æ­¥éª¤1: æŸ¥æ‰¾ç›®æ ‡è¿›ç¨‹")
            target_processes = []
            
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    proc_name = proc.info['name']
                    cmdline = ' '.join(proc.info['cmdline']) if proc.info['cmdline'] else ''
                    
                    # æ£€æŸ¥è¿›ç¨‹åæˆ–å‘½ä»¤è¡Œæ˜¯å¦åŒ¹é…
                    is_target = False
                    for name in info['process_names']:
                        if name.lower() in proc_name.lower() or name.lower() in cmdline.lower():
                            is_target = True
                            break
                    
                    if is_target:
                        target_processes.append({
                            'pid': proc.info['pid'],
                            'name': proc_name,
                            'cmdline': cmdline[:100]  # æˆªæ–­è¿‡é•¿çš„å‘½ä»¤è¡Œ
                        })
                        
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
            
            logger.info(f"æ‰¾åˆ° {len(target_processes)} ä¸ªç›®æ ‡è¿›ç¨‹")
            
            if not target_processes:
                return {
                    'editor_type': editor_type,
                    'status': 'success',
                    'message': 'æœªæ‰¾åˆ°è¿è¡Œä¸­çš„è¿›ç¨‹',
                    'killed_processes': [],
                    'remaining_processes': []
                }
            
            # ç¬¬2æ­¥: ä¼˜é›…ç»ˆæ­¢è¿›ç¨‹ (SIGTERM)
            logger.info("æ­¥éª¤2: å‘é€SIGTERMä¿¡å·")
            for proc_info in target_processes:
                try:
                    proc = psutil.Process(proc_info['pid'])
                    proc.terminate()
                    logger.info(f"å‘é€SIGTERMåˆ°è¿›ç¨‹ {proc_info['pid']}: {proc_info['name']}")
                except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
                    logger.warning(f"æ— æ³•ç»ˆæ­¢è¿›ç¨‹ {proc_info['pid']}: {e}")
            
            # ç¬¬3æ­¥: ç­‰å¾…è¿›ç¨‹é€€å‡º (æœ€å¤š10ç§’)
            logger.info("æ­¥éª¤3: ç­‰å¾…è¿›ç¨‹é€€å‡º")
            wait_time = 0
            max_wait = 10
            
            while wait_time < max_wait:
                time.sleep(1)
                wait_time += 1
                
                # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
                remaining = []
                for proc_info in target_processes:
                    try:
                        proc = psutil.Process(proc_info['pid'])
                        if proc.is_running():
                            remaining.append(proc_info)
                    except psutil.NoSuchProcess:
                        # è¿›ç¨‹å·²ç»é€€å‡º
                        killed_processes.append(proc_info)
                
                if not remaining:
                    logger.info(f"æ‰€æœ‰è¿›ç¨‹å·²é€€å‡º (è€—æ—¶ {wait_time} ç§’)")
                    break
                    
                target_processes = remaining
            
            # ç¬¬4æ­¥: å¼ºåˆ¶ç»ˆæ­¢å‰©ä½™è¿›ç¨‹ (SIGKILL)
            if target_processes:
                logger.info("æ­¥éª¤4: å¼ºåˆ¶ç»ˆæ­¢å‰©ä½™è¿›ç¨‹")
                for proc_info in target_processes:
                    try:
                        proc = psutil.Process(proc_info['pid'])
                        proc.kill()
                        logger.info(f"å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹ {proc_info['pid']}: {proc_info['name']}")
                        killed_processes.append(proc_info)
                    except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
                        logger.error(f"æ— æ³•å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹ {proc_info['pid']}: {e}")
                        remaining_processes.append(proc_info)
                
                # æœ€åæ£€æŸ¥
                time.sleep(2)
                final_remaining = []
                for proc_info in target_processes:
                    try:
                        proc = psutil.Process(proc_info['pid'])
                        if proc.is_running():
                            final_remaining.append(proc_info)
                    except psutil.NoSuchProcess:
                        pass
                
                remaining_processes = final_remaining
            
            # ç¬¬5æ­¥: ç¡®ä¿æ–‡ä»¶è®¿é—®æƒé™é‡Šæ”¾
            logger.info("æ­¥éª¤5: ç­‰å¾…æ–‡ä»¶ç³»ç»Ÿé‡Šæ”¾")
            time.sleep(2)  # ç»™æ–‡ä»¶ç³»ç»Ÿä¸€äº›æ—¶é—´æ¥é‡Šæ”¾é”å®šçš„æ–‡ä»¶
            
            result = {
                'editor_type': editor_type,
                'status': 'success' if not remaining_processes else 'partial',
                'killed_processes': killed_processes,
                'remaining_processes': remaining_processes,
                'total_found': len(killed_processes) + len(remaining_processes),
                'total_killed': len(killed_processes),
                'total_remaining': len(remaining_processes),
                'wait_time_seconds': wait_time,
                'message': f'è¿›ç¨‹ç»ˆæ­¢å®Œæˆã€‚æˆåŠŸ: {len(killed_processes)}, å‰©ä½™: {len(remaining_processes)}'
            }
            
            if remaining_processes:
                logger.warning(f"ä»æœ‰ {len(remaining_processes)} ä¸ªè¿›ç¨‹æ— æ³•ç»ˆæ­¢")
            else:
                logger.info("æ‰€æœ‰ç›®æ ‡è¿›ç¨‹å·²æˆåŠŸç»ˆæ­¢")
            
            return result
            
        except Exception as e:
            logger.error(f"è¿›ç¨‹ç®¡ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return {
                'editor_type': editor_type,
                'status': 'error',
                'error': str(e),
                'killed_processes': killed_processes,
                'remaining_processes': remaining_processes
            }
    
    def modify_telemetry_ids(self, editor_type: str) -> Dict:
        """ä¿®æ”¹é¥æµ‹ID"""
        print("ğŸ”„ æ­£åœ¨ä¿®æ”¹é¥æµ‹ID...")
        print(f"   ğŸ“ ç›®æ ‡ç¼–è¾‘å™¨: {self.EDITORS.get(editor_type, editor_type)}")
        sys.stdout.flush()
        
        editor_path = self.get_editor_path(editor_type)
        storage_path = editor_path / "User" / "globalStorage" / "storage.json"
        
        if not storage_path.exists():
            print(f"   âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {storage_path}")
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {storage_path}")
        
        print("   ğŸ“‹ åˆ›å»ºå¤‡ä»½æ–‡ä»¶...")
        # åˆ›å»ºå¤‡ä»½
        backup_path = storage_path.with_suffix('.json.bak')
        shutil.copy2(storage_path, backup_path)
        print(f"   âœ… å¤‡ä»½å·²åˆ›å»º: {backup_path.name}")
        logger.info(f"å·²åˆ›å»ºå¤‡ä»½: {backup_path}")
        
        # åˆ›å»º machine_id_backup_path å¤‡ä»½ (éœ€æ±‚ä¸­æåˆ°çš„é¢å¤–å¤‡ä»½)
        machine_id_backup_path = editor_path / "User" / "globalStorage" / "machine_id_backup.json"
        
        print("   ğŸ“– è¯»å–ç°æœ‰é…ç½®...")
        # è¯»å–ç°æœ‰é…ç½®
        with open(storage_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # è®°å½•åŸå§‹ID
        old_machine_id = config.get('telemetry.machineId', 'NOT_FOUND')
        old_device_id = config.get('telemetry.devDeviceId', 'NOT_FOUND')
        
        print(f"   ğŸ†” åŸå§‹machineId: {old_machine_id[:8]}...")
        print(f"   ğŸ†” åŸå§‹deviceId: {old_device_id[:8]}...")
        
        print("   ğŸ’¾ åˆ›å»ºIDä¸“ç”¨å¤‡ä»½...")
        # åˆ›å»ºmachine_idä¸“é—¨å¤‡ä»½
        machine_id_backup = {
            'timestamp': str(uuid.uuid4()),  # ç”¨ä½œæ—¶é—´æˆ³æ ‡è¯†
            'old_machine_id': old_machine_id,
            'old_device_id': old_device_id,
            'editor_type': editor_type
        }
        
        with open(machine_id_backup_path, 'w', encoding='utf-8') as f:
            json.dump(machine_id_backup, f, indent=2, ensure_ascii=False)
        
        print("   ğŸ² ç”Ÿæˆæ–°çš„ID...")
        # ç”Ÿæˆæ–°çš„ID
        new_machine_id = str(uuid.uuid4())
        new_device_id = str(uuid.uuid4())
        
        print(f"   ğŸ†• æ–°machineId: {new_machine_id[:8]}...")
        print(f"   ğŸ†• æ–°deviceId: {new_device_id[:8]}...")
        
        print("   ğŸ’¾ ä¿å­˜æ–°é…ç½®...")
        # æ›´æ–°é…ç½®
        config['telemetry.machineId'] = new_machine_id
        config['telemetry.devDeviceId'] = new_device_id
        
        # ä¿å­˜é…ç½®
        with open(storage_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        print("   âœ… é¥æµ‹IDä¿®æ”¹å®Œæˆï¼")
        
        result = {
            'editor_type': editor_type,
            'backup_created': str(backup_path),
            'machine_id_backup_path': str(machine_id_backup_path),
            'old_machine_id': old_machine_id,
            'new_machine_id': new_machine_id,
            'old_device_id': old_device_id,
            'new_device_id': new_device_id,
            'storage_path': str(storage_path)
        }
        
        logger.info(f"é¥æµ‹IDä¿®æ”¹å®Œæˆ: {editor_type}")
        logger.debug(f"åŸå§‹machineId: {old_machine_id}")
        logger.debug(f"æ–°machineId: {new_machine_id}")
        logger.debug(f"åŸå§‹deviceId: {old_device_id}")
        logger.debug(f"æ–°deviceId: {new_device_id}")
        return result
    
    def clean_database(self, editor_type: str) -> Dict:
        """æ¸…ç†æ•°æ®åº“ä¸­çš„augmentç›¸å…³æ•°æ®"""
        print("\nğŸ”„ æ­£åœ¨æ¸…ç†æ•°æ®åº“...")
        print(f"   ğŸ¯ ç›®æ ‡: åˆ é™¤åŒ…å«'augment'çš„æ•°æ®")
        sys.stdout.flush()
        
        editor_path = self.get_editor_path(editor_type)
        workspace_storage_path = editor_path / "User" / "workspaceStorage"
        
        if not workspace_storage_path.exists():
            print("   âš ï¸  å·¥ä½œåŒºå­˜å‚¨ç›®å½•ä¸å­˜åœ¨")
            return {'deleted_rows': 0, 'message': 'å·¥ä½œåŒºå­˜å‚¨ç›®å½•ä¸å­˜åœ¨'}
        
        total_deleted = 0
        processed_dbs = []
        
        print("   ğŸ” æŸ¥æ‰¾æ•°æ®åº“æ–‡ä»¶...")
        # æŸ¥æ‰¾æ‰€æœ‰state.vscdbæ–‡ä»¶
        db_pattern = str(workspace_storage_path / "*" / "state.vscdb")
        db_files = glob.glob(db_pattern)
        
        print(f"   ğŸ“ æ‰¾åˆ° {len(db_files)} ä¸ªæ•°æ®åº“æ–‡ä»¶")
        
        for i, db_file in enumerate(db_files, 1):
            print(f"   ğŸ—ƒï¸  å¤„ç†æ•°æ®åº“ {i}/{len(db_files)}: {Path(db_file).parent.name}")
            try:
                conn = sqlite3.connect(db_file)
                cursor = conn.cursor()
                
                # æ‰§è¡Œåˆ é™¤æ“ä½œ
                cursor.execute("DELETE FROM ItemTable WHERE key LIKE '%augment%'")
                deleted_count = cursor.rowcount
                total_deleted += deleted_count
                
                conn.commit()
                conn.close()
                
                if deleted_count > 0:
                    print(f"      âœ… åˆ é™¤äº† {deleted_count} è¡Œæ•°æ®")
                else:
                    print(f"      âšª æ— éœ€è¦åˆ é™¤çš„æ•°æ®")
                
                processed_dbs.append({
                    'db_file': db_file,
                    'deleted_rows': deleted_count
                })
                
                logger.info(f"å·²æ¸…ç†æ•°æ®åº“ {db_file}: åˆ é™¤ {deleted_count} è¡Œ")
                
            except Exception as e:
                print(f"      âŒ å¤„ç†å¤±è´¥: {e}")
                logger.error(f"æ¸…ç†æ•°æ®åº“ {db_file} æ—¶å‡ºé”™: {e}")
                processed_dbs.append({
                    'db_file': db_file,
                    'error': str(e)
                })
        
        print(f"   âœ… æ•°æ®åº“æ¸…ç†å®Œæˆï¼å…±åˆ é™¤ {total_deleted} è¡Œæ•°æ®")
        
        result = {
            'editor_type': editor_type,
            'total_deleted_rows': total_deleted,
            'deleted_rows': total_deleted,  # å…¼å®¹å­—æ®µ
            'processed_databases': processed_dbs,
            'message': f'Database cleaned successfully. Deleted {total_deleted} rows.'
        }
        
        return result
    
    def clean_workspace(self, editor_type: str) -> Dict:
        """æ¸…ç†å·¥ä½œåŒºæ–‡ä»¶"""
        print("\nğŸ”„ æ­£åœ¨æ¸…ç†å·¥ä½œåŒº...")
        print(f"   ğŸ¯ ç›®æ ‡: åˆ é™¤augmentç›¸å…³å·¥ä½œåŒºæ–‡ä»¶")
        
        editor_path = self.get_editor_path(editor_type)
        workspace_storage_path = editor_path / "User" / "workspaceStorage"
        
        if not workspace_storage_path.exists():
            print("   âš ï¸  å·¥ä½œåŒºå­˜å‚¨ç›®å½•ä¸å­˜åœ¨")
            return {'deleted_files': 0, 'message': 'å·¥ä½œåŒºå­˜å‚¨ç›®å½•ä¸å­˜åœ¨'}
        
        deleted_files = 0
        deleted_dirs = []
        
        print("   ğŸ” æ‰«æå·¥ä½œåŒºç›®å½•...")
        # æŸ¥æ‰¾åŒ…å«augmentçš„ç›®å½•
        workspace_dirs = list(workspace_storage_path.iterdir())
        print(f"   ğŸ“ æ‰¾åˆ° {len(workspace_dirs)} ä¸ªå·¥ä½œåŒºç›®å½•")
        
        processed_count = 0
        for workspace_dir in workspace_dirs:
            if workspace_dir.is_dir():
                processed_count += 1
                print(f"   ğŸ“‚ æ£€æŸ¥ç›®å½• {processed_count}/{len(workspace_dirs)}: {workspace_dir.name[:20]}...")
                
                # æ£€æŸ¥ç›®å½•ä¸­æ˜¯å¦æœ‰augmentç›¸å…³æ–‡ä»¶
                augment_files = list(workspace_dir.glob("*augment*"))
                if augment_files:
                    print(f"      ğŸ¯ å‘ç° {len(augment_files)} ä¸ªaugmentç›¸å…³æ–‡ä»¶")
                    try:
                        for file_path in augment_files:
                            if file_path.is_file():
                                file_path.unlink()
                                deleted_files += 1
                                print(f"         ğŸ—‘ï¸  åˆ é™¤æ–‡ä»¶: {file_path.name}")
                            elif file_path.is_dir() and not self._is_dangerous_path(file_path):
                                file_count = len(list(file_path.rglob("*")))
                                shutil.rmtree(file_path)
                                deleted_files += file_count
                                print(f"         ğŸ—‘ï¸  åˆ é™¤ç›®å½•: {file_path.name} ({file_count}ä¸ªæ–‡ä»¶)")
                        
                        deleted_dirs.append(str(workspace_dir))
                        print(f"      âœ… æ¸…ç†å®Œæˆ: {workspace_dir.name}")
                        logger.info(f"å·²æ¸…ç†å·¥ä½œåŒºç›®å½•: {workspace_dir}")
                        
                    except Exception as e:
                        print(f"      âŒ æ¸…ç†å¤±è´¥: {e}")
                        logger.error(f"æ¸…ç†å·¥ä½œåŒº {workspace_dir} æ—¶å‡ºé”™: {e}")
                else:
                    print(f"      âšª æ— augmentæ–‡ä»¶")
        
        print(f"   âœ… å·¥ä½œåŒºæ¸…ç†å®Œæˆï¼å…±åˆ é™¤ {deleted_files} ä¸ªæ–‡ä»¶")
        
        result = {
            'editor_type': editor_type,
            'deleted_files': deleted_files,
            'processed_directories': deleted_dirs,
            'message': f'Workspace cleaned successfully. Deleted {deleted_files} files.'
        }
        
        return result
    
    def deep_scan_augment_data(self, editor_type: str) -> Dict:
        """æ·±åº¦æ‰«ææ‰€æœ‰Augmentç›¸å…³æ•°æ® - å¤šæ–¹æ¡ˆæ£€æµ‹"""
        print("\nğŸ” æ­£åœ¨æ‰§è¡Œæ·±åº¦æ‰«æ...")
        print(f"   ğŸ¯ ç›®æ ‡: å…¨é¢æ£€æµ‹Augmentæ•°æ®ä½ç½®")

        editor_path = self.get_editor_path(editor_type)
        found_locations = {
            'globalStorage_dirs': [],
            'workspaceStorage_dirs': [],
            'database_files': [],
            'cache_files': [],
            'config_files': [],
            'other_files': []
        }

        # ä»é…ç½®è·å–æ‰©å±•IDåˆ—è¡¨
        ext_ids = self.config.get('augment_extension_ids', [
            'augmentcode.augment',
            'augmentcode.augment-vscode',
            'augment.augment'
        ])

        # æ–¹æ¡ˆ1: æ‰«æglobalStorage - ç²¾ç¡®åŒ¹é…æ‰©å±•ID
        print("   ğŸ“‚ æ–¹æ¡ˆ1: æ‰«æglobalStorage (ç²¾ç¡®åŒ¹é…)...")
        global_storage = editor_path / "User" / "globalStorage"
        if global_storage.exists():
            # ç²¾ç¡®åŒ¹é…æ‰©å±•ID
            for ext_id in ext_ids:
                ext_path = global_storage / ext_id
                if ext_path.exists():
                    found_locations['globalStorage_dirs'].append(ext_path)
                    print(f"      ğŸ¯ æ‰¾åˆ°æ‰©å±•: {ext_id}")

            # æ¨¡ç³ŠåŒ¹é…åŒ…å«augmentçš„ç›®å½•
            for item in global_storage.iterdir():
                if item.is_dir() and 'augment' in item.name.lower():
                    if item not in found_locations['globalStorage_dirs']:
                        found_locations['globalStorage_dirs'].append(item)
                        print(f"      ğŸ¯ æ‰¾åˆ°ç›®å½•: {item.name}")

                    # æ£€æŸ¥ç›®å½•å†…å®¹
                    try:
                        for sub_item in item.rglob("*"):
                            if 'augment' in str(sub_item).lower() or 'chat' in str(sub_item).lower():
                                if sub_item.is_file() and sub_item not in found_locations['other_files']:
                                    found_locations['other_files'].append(sub_item)
                    except:
                        pass

        # æ–¹æ¡ˆ2: æ‰«æworkspaceStorage - å¤šé‡æ£€æµ‹
        print("   ğŸ“‚ æ–¹æ¡ˆ2: æ‰«æworkspaceStorage (å¤šé‡æ£€æµ‹)...")
        workspace_storage = editor_path / "User" / "workspaceStorage"
        if workspace_storage.exists():
            for workspace_dir in workspace_storage.iterdir():
                if workspace_dir.is_dir():
                    should_clean = False

                    # æ£€æµ‹1: workspace.jsonå†…å®¹
                    workspace_json = workspace_dir / "workspace.json"
                    if workspace_json.exists():
                        try:
                            with open(workspace_json, 'r', encoding='utf-8') as f:
                                content = f.read().lower()
                                if any(keyword in content for keyword in ['augment', 'augmentcode']):
                                    should_clean = True
                                    print(f"      ğŸ¯ workspace.jsonåŒ¹é…: {workspace_dir.name[:20]}...")
                        except:
                            pass

                    # æ£€æµ‹2: æ‰«æaugmentç›¸å…³æ–‡ä»¶
                    try:
                        augment_files = list(workspace_dir.glob("*augment*"))
                        if augment_files:
                            should_clean = True
                            print(f"      ğŸ¯ æ–‡ä»¶ååŒ¹é…: {workspace_dir.name[:20]}... ({len(augment_files)}ä¸ªæ–‡ä»¶)")
                    except:
                        pass

                    # æ£€æµ‹3: æ£€æŸ¥state.vscdbæ•°æ®åº“
                    state_db = workspace_dir / "state.vscdb"
                    if state_db.exists():
                        try:
                            conn = sqlite3.connect(str(state_db))
                            cursor = conn.cursor()
                            cursor.execute("SELECT COUNT(*) FROM ItemTable WHERE key LIKE '%augment%'")
                            count = cursor.fetchone()[0]
                            conn.close()
                            if count > 0:
                                should_clean = True
                                print(f"      ğŸ¯ æ•°æ®åº“åŒ¹é…: {workspace_dir.name[:20]}... ({count}æ¡è®°å½•)")
                        except:
                            pass

                    if should_clean and workspace_dir not in found_locations['workspaceStorage_dirs']:
                        found_locations['workspaceStorage_dirs'].append(workspace_dir)

        # æ–¹æ¡ˆ3: æ‰«ææ•°æ®åº“ - æ‰©å±•å…³é”®è¯æ£€æµ‹
        print("   ğŸ“‚ æ–¹æ¡ˆ3: æ‰«ææ•°æ®åº“ (æ‰©å±•å…³é”®è¯)...")
        if workspace_storage.exists():
            db_pattern = str(workspace_storage / "*" / "state.vscdb")
            db_files = glob.glob(db_pattern)

            # æ‰©å±•çš„æ•°æ®åº“æ£€æµ‹å…³é”®è¯
            db_keywords = self.config.get('database_cleanup_keys', {}).get('augment_specific', [
                '%augment%', '%AugmentCode%', '%augmentcode%',
                '%chat%', '%conversation%', '%message%'
            ])

            for db_file in db_files:
                try:
                    conn = sqlite3.connect(db_file)
                    cursor = conn.cursor()

                    total_count = 0
                    for keyword in db_keywords:
                        cursor.execute("SELECT COUNT(*) FROM ItemTable WHERE key LIKE ?", (keyword,))
                        count = cursor.fetchone()[0]
                        total_count += count

                    conn.close()

                    if total_count > 0:
                        found_locations['database_files'].append((db_file, total_count))
                        print(f"      ğŸ¯ æ‰¾åˆ°æ•°æ®åº“: {Path(db_file).parent.name[:20]}... ({total_count}æ¡)")
                except:
                    pass

        # æ–¹æ¡ˆ4: å…¨å±€æ–‡ä»¶åæœç´¢ - å¤šæ¨¡å¼åŒ¹é…
        print("   ğŸ“‚ æ–¹æ¡ˆ4: å…¨å±€æ–‡ä»¶åæœç´¢ (å¤šæ¨¡å¼)...")
        search_patterns = [
            '*augment*', '*conversation*', '*chat*', '*dialog*',
            '*AugmentCode*', '*augmentcode*', '*.augment'
        ]

        try:
            for pattern in search_patterns:
                matches = list(editor_path.rglob(pattern))
                for match in matches[:20]:  # å¢åŠ æ˜¾ç¤ºæ•°é‡
                    # è¿‡æ»¤æ‰å·²ç»åœ¨å…¶ä»–åˆ—è¡¨ä¸­çš„
                    if (match not in found_locations['other_files'] and
                        match not in found_locations['globalStorage_dirs'] and
                        match not in found_locations['workspaceStorage_dirs']):

                        # åªæ·»åŠ æ–‡ä»¶ï¼Œä¸æ·»åŠ ç›®å½•ï¼ˆç›®å½•å·²åœ¨å‰é¢å¤„ç†ï¼‰
                        if match.is_file():
                            found_locations['other_files'].append(match)
                            print(f"      ğŸ¯ æ‰¾åˆ°æ–‡ä»¶: {match.name}")
        except Exception as e:
            logger.debug(f"å…¨å±€æœç´¢å‡ºé”™: {e}")

        # æ–¹æ¡ˆ5: æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„augmentè®¾ç½®
        print("   ğŸ“‚ æ–¹æ¡ˆ5: æ£€æŸ¥é…ç½®æ–‡ä»¶...")
        settings_json = editor_path / "User" / "settings.json"
        if settings_json.exists():
            try:
                with open(settings_json, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'augment' in content.lower():
                        found_locations['config_files'].append(settings_json)
                        print(f"      ğŸ¯ settings.jsonåŒ…å«augmenté…ç½®")
            except:
                pass

        keybindings_json = editor_path / "User" / "keybindings.json"
        if keybindings_json.exists():
            try:
                with open(keybindings_json, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'augment' in content.lower():
                        found_locations['config_files'].append(keybindings_json)
                        print(f"      ğŸ¯ keybindings.jsonåŒ…å«augmenté…ç½®")
            except:
                pass

        # ç»Ÿè®¡
        total_found = (
            len(found_locations['globalStorage_dirs']) +
            len(found_locations['workspaceStorage_dirs']) +
            len(found_locations['database_files']) +
            len(found_locations['other_files'])
        )

        print(f"   âœ… æ·±åº¦æ‰«æå®Œæˆï¼å…±å‘ç° {total_found} ä¸ªä½ç½®")

        return {
            'editor_type': editor_type,
            'found_locations': found_locations,
            'total_found': total_found
        }

    def clear_chat_history(self, editor_type: str) -> Dict:
        """æ¸…ç†èŠå¤©å†å²è®°å½• - ä¼˜åŒ–ç‰ˆï¼Œé’ˆå¯¹Augmentæ‰©å±•"""
        print("\nğŸ”„ æ­£åœ¨æ¸…ç†èŠå¤©å†å²...")
        print(f"   ğŸ¯ ç›®æ ‡: åˆ é™¤èŠå¤©è®°å½•å’Œaugmentç¼“å­˜")

        editor_path = self.get_editor_path(editor_type)
        global_storage = editor_path / "User" / "globalStorage"
        workspace_storage = editor_path / "User" / "workspaceStorage"

        # æ‰©å±•çš„å¯èƒ½IDï¼ˆAugmentæ‰©å±•çš„å„ç§å˜ä½“ï¼‰
        augment_extension_ids = [
            'augmentcode.augment',
            'augmentcode.augment-vscode',
            'augment.augment',
            'vscode-augment',
            'augment-code',
            'augmentcode.vscode-augment'
        ]

        # æ›´å…¨é¢çš„èŠå¤©å†å²å­˜å‚¨ä½ç½®
        chat_paths = []

        # 1. globalStorageä¸‹çš„æ‰©å±•ç›®å½•
        if global_storage.exists():
            for ext_id in augment_extension_ids:
                ext_path = global_storage / ext_id
                if ext_path.exists():
                    chat_paths.append(ext_path)

            # é€šé…ç¬¦åŒ¹é…ä»»ä½•åŒ…å«augmentçš„ç›®å½•
            for item in global_storage.iterdir():
                if item.is_dir() and 'augment' in item.name.lower():
                    if item not in chat_paths:
                        chat_paths.append(item)

        # 2. workspaceStorageä¸‹çš„æ‰©å±•æ•°æ®
        if workspace_storage.exists():
            for workspace_dir in workspace_storage.iterdir():
                if workspace_dir.is_dir():
                    # æ£€æŸ¥workspace.jsonä¸­æ˜¯å¦åŒ…å«augment
                    workspace_json = workspace_dir / "workspace.json"
                    if workspace_json.exists():
                        try:
                            with open(workspace_json, 'r', encoding='utf-8') as f:
                                content = f.read()
                                if 'augment' in content.lower():
                                    chat_paths.append(workspace_dir)
                        except:
                            pass

                    # æ£€æŸ¥æ˜¯å¦æœ‰augmentç›¸å…³æ–‡ä»¶
                    augment_files = list(workspace_dir.glob("*augment*"))
                    if augment_files and workspace_dir not in chat_paths:
                        chat_paths.append(workspace_dir)

        # 3. å…¶ä»–å¯èƒ½çš„ä½ç½®
        additional_paths = [
            editor_path / "User" / "globalStorage" / "chat",
            editor_path / "CachedExtensions" / "*augment*",
            editor_path / "User" / "History" / "*augment*",
        ]

        for path_pattern in additional_paths:
            if "*" in str(path_pattern):
                matching = glob.glob(str(path_pattern))
                chat_paths.extend([Path(p) for p in matching if Path(p).exists()])
            elif path_pattern.exists():
                chat_paths.append(path_pattern)

        # å»é‡
        chat_paths = list(set(chat_paths))

        deleted_files = 0
        processed_paths = []

        print(f"   ğŸ” æ‰¾åˆ° {len(chat_paths)} ä¸ªéœ€è¦æ¸…ç†çš„ä½ç½®...")

        for i, path_obj in enumerate(chat_paths, 1):
            print(f"   ğŸ“‚ æ¸…ç†ä½ç½® {i}/{len(chat_paths)}: {path_obj.name}")

            try:
                if not self._is_dangerous_path(path_obj):
                    if path_obj.is_file():
                        path_obj.unlink()
                        deleted_files += 1
                        print(f"      âœ… åˆ é™¤æ–‡ä»¶")
                    elif path_obj.is_dir():
                        file_count = len(list(path_obj.rglob("*")))
                        shutil.rmtree(path_obj)
                        deleted_files += file_count
                        print(f"      âœ… åˆ é™¤ç›®å½• ({file_count}ä¸ªæ–‡ä»¶)")

                    processed_paths.append(str(path_obj))
                else:
                    print(f"      âš ï¸  è·³è¿‡å±é™©è·¯å¾„")

            except Exception as e:
                print(f"      âŒ åˆ é™¤å¤±è´¥: {e}")
                logger.error(f"æ¸…ç†èŠå¤©å†å² {path_obj} æ—¶å‡ºé”™: {e}")

        # 4. æ¸…ç†æ•°æ®åº“ä¸­çš„èŠå¤©è®°å½•
        print("   ğŸ—„ï¸  æ¸…ç†æ•°æ®åº“ä¸­çš„èŠå¤©è®°å½•...")
        db_cleaned = 0
        if workspace_storage.exists():
            db_pattern = str(workspace_storage / "*" / "state.vscdb")
            db_files = glob.glob(db_pattern)

            chat_keys = [
                '%chat%', '%conversation%', '%message%', '%dialog%',
                '%augment.chat%', '%augment.history%', '%augment.session%'
            ]

            for db_file in db_files:
                try:
                    conn = sqlite3.connect(db_file)
                    cursor = conn.cursor()

                    for key_pattern in chat_keys:
                        cursor.execute("DELETE FROM ItemTable WHERE key LIKE ?", (key_pattern,))
                        deleted_count = cursor.rowcount
                        if deleted_count > 0:
                            db_cleaned += deleted_count
                            print(f"      ğŸ—‘ï¸  æ¸…ç† {key_pattern}: {deleted_count} è¡Œ")

                    conn.commit()
                    conn.close()

                except Exception as e:
                    logger.error(f"æ¸…ç†æ•°æ®åº“ {db_file} æ—¶å‡ºé”™: {e}")

        total_deleted = deleted_files + db_cleaned
        print(f"   âœ… èŠå¤©å†å²æ¸…ç†å®Œæˆï¼æ–‡ä»¶: {deleted_files}, æ•°æ®åº“: {db_cleaned}, æ€»è®¡: {total_deleted}")

        result = {
            'editor_type': editor_type,
            'deleted_files': deleted_files,
            'deleted_db_rows': db_cleaned,
            'total_deleted': total_deleted,
            'processed_paths': processed_paths,
            'message': f'èŠå¤©å†å²æ¸…ç†å®Œæˆã€‚åˆ é™¤äº† {deleted_files} ä¸ªæ–‡ä»¶å’Œ {db_cleaned} æ¡æ•°æ®åº“è®°å½•ã€‚'
        }

        return result
    
    def clean_extension_cache(self, editor_type: str) -> Dict:
        """æ¸…ç†æ‰©å±•ç¼“å­˜æ•°æ®"""
        print("\nğŸ”„ æ­£åœ¨æ¸…ç†æ‰©å±•ç¼“å­˜...")
        print(f"   ğŸ¯ ç›®æ ‡: åˆ é™¤æ‰©å±•ç¼“å­˜å’Œä¸´æ—¶æ–‡ä»¶")
        sys.stdout.flush()
        
        editor_path = self.get_editor_path(editor_type)
        
        # æ‰©å±•ç¼“å­˜è·¯å¾„
        cache_paths = [
            editor_path / "CachedExtensions",
            editor_path / "CachedExtensionVSIXs", 
            editor_path / "extensions" / ".obsolete",
            editor_path / "User" / "globalStorage" / "*cache*",
            editor_path / "GPUCache",
            editor_path / "DawnGraphiteCache"
        ]
        
        deleted_files = 0
        processed_paths = []
        
        print(f"   ğŸ” æ‰«æ {len(cache_paths)} ä¸ªç¼“å­˜ä½ç½®...")
        
        for i, path_pattern in enumerate(cache_paths, 1):
            print(f"   ğŸ“‚ æ£€æŸ¥ç¼“å­˜ {i}/{len(cache_paths)}: {path_pattern.name}")
            
            if "*" in str(path_pattern):
                matching_paths = glob.glob(str(path_pattern))
                for match_path in matching_paths:
                    path_obj = Path(match_path)
                    if path_obj.exists():
                        try:
                            if not self._is_dangerous_path(path_obj):
                                if path_obj.is_file():
                                    path_obj.unlink()
                                    deleted_files += 1
                                elif path_obj.is_dir():
                                    file_count = len(list(path_obj.rglob("*")))
                                    shutil.rmtree(path_obj)
                                    deleted_files += file_count
                                processed_paths.append(str(path_obj))
                                print(f"      âœ… æ¸…ç†: {path_obj.name}")
                            else:
                                print(f"      âš ï¸  è·³è¿‡å±é™©è·¯å¾„: {path_obj}")
                        except Exception as e:
                            print(f"      âŒ æ¸…ç†å¤±è´¥: {e}")
                            logger.error(f"æ¸…ç†ç¼“å­˜ {path_obj} æ—¶å‡ºé”™: {e}")
            else:
                if path_pattern.exists():
                    try:
                        if path_pattern.is_file():
                            path_pattern.unlink()
                            deleted_files += 1
                        elif path_pattern.is_dir() and not self._is_dangerous_path(path_pattern):
                            file_count = len(list(path_pattern.rglob("*")))
                            shutil.rmtree(path_pattern)
                            deleted_files += file_count
                        processed_paths.append(str(path_pattern))
                        print(f"      âœ… æ¸…ç†: {path_pattern.name}")
                    except Exception as e:
                        print(f"      âŒ æ¸…ç†å¤±è´¥: {e}")
        
        print(f"   âœ… æ‰©å±•ç¼“å­˜æ¸…ç†å®Œæˆï¼å…±åˆ é™¤ {deleted_files} ä¸ªæ–‡ä»¶")
        
        return {
            'editor_type': editor_type,
            'deleted_files': deleted_files,
            'processed_paths': processed_paths,
            'message': f'æ‰©å±•ç¼“å­˜æ¸…ç†å®Œæˆã€‚åˆ é™¤äº† {deleted_files} ä¸ªæ–‡ä»¶ã€‚'
        }
    
    def clean_logs_and_crashes(self, editor_type: str) -> Dict:
        """æ¸…ç†æ—¥å¿—å’Œå´©æºƒè½¬å‚¨"""
        print("\nğŸ”„ æ­£åœ¨æ¸…ç†æ—¥å¿—å’Œå´©æºƒæ–‡ä»¶...")
        print(f"   ğŸ¯ ç›®æ ‡: åˆ é™¤æ‰€æœ‰æ—¥å¿—å’Œå´©æºƒè½¬å‚¨")
        
        editor_path = self.get_editor_path(editor_type)
        
        # æ ¹æ®æ“ä½œç³»ç»Ÿè®¾ç½®æ—¥å¿—è·¯å¾„
        if self.current_os == 'windows':
            log_paths = [
                editor_path / "logs",
                editor_path / "crashes",
                editor_path / "User" / "logs", 
                self.home_path / "AppData" / "Local" / self.EDITORS[editor_type] / "logs",
                Path(os.environ.get('TEMP', '')) / f"{self.EDITORS[editor_type].lower()}-*"
            ]
        elif self.current_os == 'darwin':
            log_paths = [
                editor_path / "logs",
                editor_path / "crashes",
                editor_path / "User" / "logs",
                self.home_path / "Library" / "Logs" / self.EDITORS[editor_type],
                Path("/tmp") / f"{self.EDITORS[editor_type].lower()}-*"
            ]
        else:  # Linux
            log_paths = [
                editor_path / "logs",
                editor_path / "crashes", 
                editor_path / "User" / "logs",
                self.home_path / ".cache" / self.EDITORS[editor_type] / "logs",
                Path("/tmp") / f"{self.EDITORS[editor_type].lower()}-*"
            ]
        
        deleted_files = 0
        processed_paths = []
        
        for path_pattern in log_paths:
            if "*" in str(path_pattern):
                matching_paths = glob.glob(str(path_pattern))
                for match_path in matching_paths:
                    path_obj = Path(match_path)
                    if path_obj.exists():
                        try:
                            if path_obj.is_dir() and not self._is_dangerous_path(path_obj):
                                file_count = len(list(path_obj.rglob("*")))
                                shutil.rmtree(path_obj)
                                deleted_files += file_count
                                processed_paths.append(str(path_obj))
                                print(f"      âœ… æ¸…ç†æ—¥å¿—ç›®å½•: {path_obj.name}")
                        except Exception as e:
                            print(f"      âŒ æ¸…ç†å¤±è´¥: {e}")
            else:
                if path_pattern.exists() and not self._is_dangerous_path(path_pattern):
                    try:
                        file_count = len(list(path_pattern.rglob("*")))
                        shutil.rmtree(path_pattern)
                        deleted_files += file_count
                        processed_paths.append(str(path_pattern))
                        print(f"      âœ… æ¸…ç†: {path_pattern.name}")
                    except Exception as e:
                        print(f"      âŒ æ¸…ç†å¤±è´¥: {e}")
        
        print(f"   âœ… æ—¥å¿—æ¸…ç†å®Œæˆï¼å…±åˆ é™¤ {deleted_files} ä¸ªæ–‡ä»¶")
        
        return {
            'editor_type': editor_type,
            'deleted_files': deleted_files,
            'processed_paths': processed_paths,
            'message': f'æ—¥å¿—å’Œå´©æºƒæ–‡ä»¶æ¸…ç†å®Œæˆã€‚åˆ é™¤äº† {deleted_files} ä¸ªæ–‡ä»¶ã€‚'
        }
    
    def clean_browser_cache(self, editor_type: str) -> Dict:
        """æ¸…ç†æµè§ˆå™¨ç¼“å­˜"""
        print("\nğŸ”„ æ­£åœ¨æ¸…ç†æµè§ˆå™¨ç¼“å­˜...")
        print(f"   ğŸ¯ ç›®æ ‡: åˆ é™¤WebViewå’Œæ¸²æŸ“ç¼“å­˜")
        
        editor_path = self.get_editor_path(editor_type)
        
        browser_cache_paths = [
            editor_path / "GPUCache",
            editor_path / "DawnGraphiteCache",
            editor_path / "WebviewCache",
            editor_path / "CachedData",
            editor_path / "blob_storage",
            editor_path / "Local Storage",
            editor_path / "Session Storage"
        ]
        
        deleted_files = 0
        processed_paths = []
        
        for cache_path in browser_cache_paths:
            if cache_path.exists():
                try:
                    if cache_path.is_file():
                        cache_path.unlink()
                        deleted_files += 1
                    elif cache_path.is_dir() and not self._is_dangerous_path(cache_path):
                        file_count = len(list(cache_path.rglob("*")))
                        shutil.rmtree(cache_path)
                        deleted_files += file_count
                    processed_paths.append(str(cache_path))
                    print(f"      âœ… æ¸…ç†: {cache_path.name}")
                except Exception as e:
                    print(f"      âŒ æ¸…ç†å¤±è´¥: {e}")
        
        print(f"   âœ… æµè§ˆå™¨ç¼“å­˜æ¸…ç†å®Œæˆï¼å…±åˆ é™¤ {deleted_files} ä¸ªæ–‡ä»¶")
        
        return {
            'editor_type': editor_type,
            'deleted_files': deleted_files,
            'processed_paths': processed_paths,
            'message': f'æµè§ˆå™¨ç¼“å­˜æ¸…ç†å®Œæˆã€‚åˆ é™¤äº† {deleted_files} ä¸ªæ–‡ä»¶ã€‚'
        }
    
    def clean_user_settings(self, editor_type: str) -> Dict:
        """æ¸…ç†ç”¨æˆ·è®¾ç½®ä¸­çš„AIç›¸å…³é…ç½®"""
        print("\nğŸ”„ æ­£åœ¨æ¸…ç†ç”¨æˆ·è®¾ç½®...")
        print(f"   ğŸ¯ ç›®æ ‡: æ¸…ç†AIå’Œaugmentç›¸å…³è®¾ç½®")
        
        editor_path = self.get_editor_path(editor_type)
        settings_path = editor_path / "User" / "settings.json"
        keybindings_path = editor_path / "User" / "keybindings.json"
        
        cleaned_items = 0
        backup_files = []
        
        # æ¸…ç†settings.json
        if settings_path.exists():
            try:
                backup_path = settings_path.with_suffix('.json.settings_bak')
                shutil.copy2(settings_path, backup_path)
                backup_files.append(str(backup_path))
                
                with open(settings_path, 'r', encoding='utf-8') as f:
                    settings = json.load(f)
                
                # éœ€è¦æ¸…ç†çš„è®¾ç½®é¡¹
                ai_related_keys = [
                    'augment', 'copilot', 'tabnine', 'codeium', 'continue',
                    'telemetry.enableTelemetry', 'telemetry.enableCrashReporter'
                ]
                
                for key in list(settings.keys()):
                    if any(ai_key in key.lower() for ai_key in ai_related_keys):
                        del settings[key]
                        cleaned_items += 1
                        print(f"      ğŸ—‘ï¸  æ¸…ç†è®¾ç½®é¡¹: {key}")
                
                with open(settings_path, 'w', encoding='utf-8') as f:
                    json.dump(settings, f, indent=2, ensure_ascii=False)
                
            except Exception as e:
                print(f"      âŒ æ¸…ç†settings.jsonå¤±è´¥: {e}")
        
        # æ¸…ç†keybindings.json
        if keybindings_path.exists():
            try:
                backup_path = keybindings_path.with_suffix('.json.keybindings_bak')
                shutil.copy2(keybindings_path, backup_path)
                backup_files.append(str(backup_path))
                
                with open(keybindings_path, 'r', encoding='utf-8') as f:
                    keybindings = json.load(f)
                
                # è¿‡æ»¤augmentç›¸å…³çš„å¿«æ·é”®
                original_count = len(keybindings)
                keybindings = [kb for kb in keybindings 
                             if not any(ai_key in str(kb).lower() for ai_key in ['augment', 'copilot', 'ai'])]
                cleaned_items += original_count - len(keybindings)
                
                with open(keybindings_path, 'w', encoding='utf-8') as f:
                    json.dump(keybindings, f, indent=2, ensure_ascii=False)
                    
            except Exception as e:
                print(f"      âŒ æ¸…ç†keybindings.jsonå¤±è´¥: {e}")
        
        print(f"   âœ… ç”¨æˆ·è®¾ç½®æ¸…ç†å®Œæˆï¼æ¸…ç†äº† {cleaned_items} ä¸ªé…ç½®é¡¹")
        
        return {
            'editor_type': editor_type,
            'cleaned_items': cleaned_items,
            'backup_files': backup_files,
            'message': f'ç”¨æˆ·è®¾ç½®æ¸…ç†å®Œæˆã€‚æ¸…ç†äº† {cleaned_items} ä¸ªé…ç½®é¡¹ã€‚'
        }
    
    def clean_network_cache(self, editor_type: str) -> Dict:
        """æ¸…ç†ç½‘ç»œç¼“å­˜"""
        print("\nğŸ”„ æ­£åœ¨æ¸…ç†ç½‘ç»œç¼“å­˜...")
        print(f"   ğŸ¯ ç›®æ ‡: åˆ é™¤HTTPç¼“å­˜å’Œç½‘ç»œæ•°æ®")
        
        editor_path = self.get_editor_path(editor_type)
        
        # æ ¹æ®æ“ä½œç³»ç»Ÿè®¾ç½®ç½‘ç»œç¼“å­˜è·¯å¾„
        if self.current_os == 'windows':
            network_cache_paths = [
                editor_path / "HTTPCache",
                editor_path / "Code Cache",
                editor_path / "Network Persistent State",
                editor_path / "TransportSecurity",
                self.home_path / "AppData" / "Local" / self.EDITORS[editor_type] / "http-cache"
            ]
        elif self.current_os == 'darwin':
            network_cache_paths = [
                editor_path / "HTTPCache",
                editor_path / "Code Cache",
                editor_path / "Network Persistent State",
                editor_path / "TransportSecurity",
                self.home_path / "Library" / "Caches" / self.EDITORS[editor_type] / "http-cache"
            ]
        else:  # Linux
            network_cache_paths = [
                editor_path / "HTTPCache",
                editor_path / "Code Cache",
                editor_path / "Network Persistent State",
                editor_path / "TransportSecurity",
                self.home_path / ".cache" / self.EDITORS[editor_type] / "http-cache"
            ]
        
        deleted_files = 0
        processed_paths = []
        
        for cache_path in network_cache_paths:
            if cache_path.exists():
                try:
                    if cache_path.is_file():
                        cache_path.unlink()
                        deleted_files += 1
                    elif cache_path.is_dir() and not self._is_dangerous_path(cache_path):
                        file_count = len(list(cache_path.rglob("*")))
                        shutil.rmtree(cache_path)
                        deleted_files += file_count
                    processed_paths.append(str(cache_path))
                    print(f"      âœ… æ¸…ç†: {cache_path.name}")
                except Exception as e:
                    print(f"      âŒ æ¸…ç†å¤±è´¥: {e}")
        
        print(f"   âœ… ç½‘ç»œç¼“å­˜æ¸…ç†å®Œæˆï¼å…±åˆ é™¤ {deleted_files} ä¸ªæ–‡ä»¶")
        
        return {
            'editor_type': editor_type,
            'deleted_files': deleted_files,
            'processed_paths': processed_paths,
            'message': f'ç½‘ç»œç¼“å­˜æ¸…ç†å®Œæˆã€‚åˆ é™¤äº† {deleted_files} ä¸ªæ–‡ä»¶ã€‚'
        }
    
    def clean_temporary_files(self, editor_type: str) -> Dict:
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶ (è·¨å¹³å°)"""
        print("\nğŸ”„ æ­£åœ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        print(f"   ğŸ¯ ç›®æ ‡: åˆ é™¤ä¸´æ—¶æ–‡ä»¶å’Œé”æ–‡ä»¶")
        
        # æ ¹æ®æ“ä½œç³»ç»Ÿè®¾ç½®ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        if self.current_os == 'windows':
            temp_base = Path(os.environ.get('TEMP', self.home_path / 'AppData' / 'Local' / 'Temp'))
            temp_paths = [
                temp_base / f"*{self.EDITORS[editor_type].lower()}*",
                temp_base / "*vscode*",
                temp_base / "*augment*",
                self.home_path / "AppData" / "Local" / self.EDITORS[editor_type],
                Path(os.environ.get('LOCALAPPDATA', self.home_path / 'AppData' / 'Local')) / self.EDITORS[editor_type]
            ]
        elif self.current_os == 'darwin':
            temp_paths = [
                Path("/tmp") / f"*{self.EDITORS[editor_type].lower()}*",
                Path("/tmp") / "*vscode*", 
                Path("/tmp") / "*augment*",
                self.home_path / "Library" / "Caches" / self.EDITORS[editor_type],
                Path("/var/tmp") / f"*{self.EDITORS[editor_type].lower()}*"
            ]
        else:  # Linux
            temp_paths = [
                Path("/tmp") / f"*{self.EDITORS[editor_type].lower()}*",
                Path("/tmp") / "*vscode*",
                Path("/tmp") / "*augment*",
                self.home_path / ".cache" / self.EDITORS[editor_type],
                Path("/var/tmp") / f"*{self.EDITORS[editor_type].lower()}*"
            ]
        
        deleted_files = 0
        processed_paths = []
        
        for path_pattern in temp_paths:
            if "*" in str(path_pattern):
                try:
                    matching_paths = glob.glob(str(path_pattern))
                    for match_path in matching_paths:
                        path_obj = Path(match_path)
                        if path_obj.exists() and not self._is_dangerous_path(path_obj):
                            try:
                                if path_obj.is_file():
                                    path_obj.unlink()
                                    deleted_files += 1
                                elif path_obj.is_dir():
                                    file_count = len(list(path_obj.rglob("*")))
                                    shutil.rmtree(path_obj)
                                    deleted_files += file_count
                                processed_paths.append(str(path_obj))
                                print(f"      âœ… æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {path_obj.name}")
                            except Exception as e:
                                print(f"      âŒ æ¸…ç†å¤±è´¥: {e}")
                except Exception as e:
                    print(f"      âŒ æ‰«æå¤±è´¥: {e}")
            else:
                if path_pattern.exists() and not self._is_dangerous_path(path_pattern):
                    try:
                        if path_pattern.is_file():
                            path_pattern.unlink()
                            deleted_files += 1
                        elif path_pattern.is_dir() and not self._is_dangerous_path(path_pattern):
                            file_count = len(list(path_pattern.rglob("*")))
                            shutil.rmtree(path_pattern)
                            deleted_files += file_count
                        processed_paths.append(str(path_pattern))
                        print(f"      âœ… æ¸…ç†: {path_pattern.name}")
                    except Exception as e:
                        print(f"      âŒ æ¸…ç†å¤±è´¥: {e}")
        
        print(f"   âœ… ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆï¼å…±åˆ é™¤ {deleted_files} ä¸ªæ–‡ä»¶")
        
        return {
            'editor_type': editor_type,
            'deleted_files': deleted_files,
            'processed_paths': processed_paths,
            'message': f'ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆã€‚åˆ é™¤äº† {deleted_files} ä¸ªæ–‡ä»¶ã€‚'
        }
    
    def clean_augment_deep(self, editor_type: str) -> Dict:
        """æ·±åº¦æ¸…ç†Augmentç›¸å…³æ•°æ® - åŸºäºJSåˆ†æå‘ç°"""
        print("\nğŸ”„ æ­£åœ¨æ‰§è¡ŒAugmentæ·±åº¦æ¸…ç†...")
        print(f"   ğŸ¯ ç›®æ ‡: åŸºäºJSåˆ†æçš„æ·±åº¦æ•°æ®æ¸…ç†")
        
        editor_path = self.get_editor_path(editor_type)
        
        # åŸºäºåˆ†æå‘ç°çš„å…³é”®æ¸…ç†ç›®æ ‡
        deep_clean_patterns = [
            # å­˜å‚¨ç›¸å…³
            "**/*augment*",
            "**/*telemetry*", 
            "**/*analytics*",
            "**/*tracking*",
            "**/*session*",
            "**/*machine*",
            "**/*device*",
            "**/*client*",
            
            # ç¼“å­˜ç›¸å…³
            "**/Code Cache/**",
            "**/GPUCache/**", 
            "**/DawnGraphiteCache/**",
            "**/CachedData/**",
            "**/blob_storage/**",
            "**/Local Storage/**",
            "**/Session Storage/**",
            "**/IndexedDB/**",
            
            # ç½‘ç»œç¼“å­˜
            "**/HTTPCache/**",
            "**/NetworkPersistentState/**",
            "**/TransportSecurity/**",
            
            # æ—¥å¿—å’Œè°ƒè¯•
            "**/logs/**/*.log",
            "**/crashes/**",
            "**/*.sqlite",
            "**/*.sqlite3", 
            "**/*.db",
            "**/debugging/**"
        ]
        
        deleted_files = 0
        processed_patterns = []
        
        print(f"   ğŸ” æ‰«æ {len(deep_clean_patterns)} ä¸ªæ·±åº¦æ¨¡å¼...")
        
        for i, pattern in enumerate(deep_clean_patterns, 1):
            print(f"   ğŸ“‚ æ¸…ç†æ¨¡å¼ {i}/{len(deep_clean_patterns)}: {pattern}")
            
            try:
                # æ­£ç¡®å¤„ç†globæ¨¡å¼
                if pattern.startswith("**/"):
                    # å¯¹äº **/ å¼€å¤´çš„æ¨¡å¼ï¼Œä½¿ç”¨rglob
                    clean_pattern = pattern[3:]  # ç§»é™¤ **/
                    matching_paths = list(editor_path.rglob(clean_pattern))
                else:
                    # å¯¹äºæ™®é€šæ¨¡å¼ï¼Œä½¿ç”¨glob
                    matching_paths = list(editor_path.glob(pattern))
                
                if matching_paths:
                    print(f"      ğŸ¯ æ‰¾åˆ° {len(matching_paths)} ä¸ªåŒ¹é…é¡¹")
                    
                    for path_obj in matching_paths:
                        try:
                            if path_obj.is_file():
                                path_obj.unlink()
                                deleted_files += 1
                                print(f"         ğŸ—‘ï¸  åˆ é™¤æ–‡ä»¶: {path_obj.name}")
                            elif path_obj.is_dir() and not self._is_dangerous_path(path_obj):
                                file_count = len(list(path_obj.rglob("*")))
                                shutil.rmtree(path_obj)
                                deleted_files += file_count
                                print(f"         ğŸ—‘ï¸  åˆ é™¤ç›®å½•: {path_obj.name} ({file_count}ä¸ªæ–‡ä»¶)")
                        except Exception as e:
                            print(f"         âŒ åˆ é™¤å¤±è´¥: {e}")
                    
                    processed_patterns.append({
                        'pattern': pattern,
                        'matches': len(matching_paths),
                        'status': 'processed'
                    })
                else:
                    print(f"      âšª æ— åŒ¹é…æ–‡ä»¶")
                    
            except Exception as e:
                print(f"      âŒ å¤„ç†æ¨¡å¼å¤±è´¥: {e}")
                processed_patterns.append({
                    'pattern': pattern,
                    'error': str(e),
                    'status': 'error'
                })
        
        print(f"   âœ… Augmentæ·±åº¦æ¸…ç†å®Œæˆï¼å…±åˆ é™¤ {deleted_files} ä¸ªæ–‡ä»¶")
        
        return {
            'editor_type': editor_type,
            'deleted_files': deleted_files,
            'processed_patterns': processed_patterns,
            'pattern_count': len(deep_clean_patterns),
            'message': f'Augmentæ·±åº¦æ¸…ç†å®Œæˆã€‚åˆ é™¤äº† {deleted_files} ä¸ªæ–‡ä»¶ã€‚'
        }
    
    def clean_analytics_data(self, editor_type: str) -> Dict:
        """æ¸…ç†åˆ†æå’Œé¥æµ‹æ•°æ® - åŸºäºJSåˆ†æ"""
        print("\nğŸ”„ æ­£åœ¨æ¸…ç†åˆ†ææ•°æ®...")
        print(f"   ğŸ¯ ç›®æ ‡: åˆ é™¤æ‰€æœ‰analyticså’Œé¥æµ‹æ•°æ®")
        
        editor_path = self.get_editor_path(editor_type)
        workspace_storage_path = editor_path / "User" / "workspaceStorage"
        
        deleted_files = 0
        cleaned_databases = 0
        
        # æ·±åº¦æ¸…ç†æ•°æ®åº“ä¸­çš„åˆ†ææ•°æ®
        if workspace_storage_path.exists():
            db_pattern = str(workspace_storage_path / "*" / "state.vscdb")
            db_files = glob.glob(db_pattern)
            
            # åŸºäºJSåˆ†æå‘ç°çš„å…³é”®è¯
            analytics_keys = [
                '%analytics%', '%telemetry%', '%tracking%', '%metrics%',
                '%sessionId%', '%deviceId%', '%machineId%', '%clientId%',
                '%fingerprint%', '%userAgent%', '%platform%', '%augment%',
                '%AugmentExtension%', '%vscode-augment%', '%Fix with Augment%'
            ]
            
            for db_file in db_files:
                try:
                    conn = sqlite3.connect(db_file)
                    cursor = conn.cursor()
                    
                    for key_pattern in analytics_keys:
                        cursor.execute("DELETE FROM ItemTable WHERE key LIKE ?", (key_pattern,))
                        deleted_count = cursor.rowcount
                        if deleted_count > 0:
                            cleaned_databases += deleted_count
                            print(f"      ğŸ—‘ï¸  æ¸…ç† {key_pattern}: {deleted_count} è¡Œ")
                    
                    conn.commit()
                    conn.close()
                    
                except Exception as e:
                    print(f"      âŒ æ•°æ®åº“æ¸…ç†å¤±è´¥: {e}")
        
        print(f"   âœ… åˆ†ææ•°æ®æ¸…ç†å®Œæˆï¼æ•°æ®åº“æ¸…ç†: {cleaned_databases} è¡Œ")
        
        return {
            'editor_type': editor_type,
            'cleaned_database_rows': cleaned_databases,
            'message': f'åˆ†ææ•°æ®æ¸…ç†å®Œæˆã€‚æ¸…ç†äº† {cleaned_databases} è¡Œæ•°æ®ã€‚'
        }
    
    def clean_vscode_cdn_cache(self, editor_type: str) -> Dict:
        """æ¸…ç†VSCode CDNç¼“å­˜"""
        print("\nğŸ”„ æ­£åœ¨æ¸…ç†VSCode CDNç¼“å­˜...")
        print(f"   ğŸ¯ ç›®æ ‡: æ¸…ç†*.vscode-cdn.netç›¸å…³ç¼“å­˜")
        
        editor_path = self.get_editor_path(editor_type)
        
        # æ ¹æ®æ“ä½œç³»ç»Ÿè®¾ç½®CDNç¼“å­˜è·¯å¾„
        if self.current_os == 'windows':
            cdn_cache_paths = [
                editor_path / "CachedData",
                editor_path / "Code Cache" / "js",
                editor_path / "Code Cache" / "wasm", 
                self.home_path / "AppData" / "Local" / self.EDITORS[editor_type] / "cdn-cache",
                editor_path / "User" / "globalStorage" / "*cdn*",
                editor_path / "User" / "globalStorage" / "*vscode-cdn*"
            ]
        elif self.current_os == 'darwin':
            cdn_cache_paths = [
                editor_path / "CachedData",
                editor_path / "Code Cache" / "js",
                editor_path / "Code Cache" / "wasm", 
                self.home_path / "Library" / "Caches" / self.EDITORS[editor_type] / "cdn-cache",
                editor_path / "User" / "globalStorage" / "*cdn*",
                editor_path / "User" / "globalStorage" / "*vscode-cdn*"
            ]
        else:  # Linux
            cdn_cache_paths = [
                editor_path / "CachedData",
                editor_path / "Code Cache" / "js",
                editor_path / "Code Cache" / "wasm", 
                self.home_path / ".cache" / self.EDITORS[editor_type] / "cdn-cache",
                editor_path / "User" / "globalStorage" / "*cdn*",
                editor_path / "User" / "globalStorage" / "*vscode-cdn*"
            ]
        
        deleted_files = 0
        processed_paths = []
        
        print(f"   ğŸ” æ‰«æ {len(cdn_cache_paths)} ä¸ªCDNç¼“å­˜ä½ç½®...")
        
        for i, path_pattern in enumerate(cdn_cache_paths, 1):
            print(f"   ğŸ“‚ æ£€æŸ¥CDNç¼“å­˜ {i}/{len(cdn_cache_paths)}: {path_pattern.name}")
            
            if "*" in str(path_pattern):
                try:
                    matching_paths = list(path_pattern.parent.glob(path_pattern.name))
                    for path_obj in matching_paths:
                        if path_obj.exists() and not self._is_dangerous_path(path_obj):
                            try:
                                if path_obj.is_file():
                                    path_obj.unlink()
                                    deleted_files += 1
                                elif path_obj.is_dir():
                                    file_count = len(list(path_obj.rglob("*")))
                                    shutil.rmtree(path_obj)
                                    deleted_files += file_count
                                processed_paths.append(str(path_obj))
                                print(f"      âœ… æ¸…ç†CDNç¼“å­˜: {path_obj.name}")
                            except Exception as e:
                                print(f"      âŒ æ¸…ç†å¤±è´¥: {e}")
                except Exception as e:
                    print(f"      âŒ æ‰«æå¤±è´¥: {e}")
            else:
                if path_pattern.exists() and not self._is_dangerous_path(path_pattern):
                    try:
                        if path_pattern.is_file():
                            path_pattern.unlink()
                            deleted_files += 1
                        elif path_pattern.is_dir():
                            file_count = len(list(path_pattern.rglob("*")))
                            shutil.rmtree(path_pattern)
                            deleted_files += file_count
                        processed_paths.append(str(path_pattern))
                        print(f"      âœ… æ¸…ç†: {path_pattern.name}")
                    except Exception as e:
                        print(f"      âŒ æ¸…ç†å¤±è´¥: {e}")
        
        print(f"   âœ… CDNç¼“å­˜æ¸…ç†å®Œæˆï¼å…±åˆ é™¤ {deleted_files} ä¸ªæ–‡ä»¶")
        
        return {
            'editor_type': editor_type,
            'deleted_files': deleted_files,
            'processed_paths': processed_paths,
            'message': f'VSCode CDNç¼“å­˜æ¸…ç†å®Œæˆã€‚åˆ é™¤äº† {deleted_files} ä¸ªæ–‡ä»¶ã€‚'
        }
    
    def _is_dangerous_path(self, path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯å±é™©è·¯å¾„ (è·¨å¹³å°) - å¢å¼ºç‰ˆ"""
        path_str = str(path).lower()

        # ä»é…ç½®æ–‡ä»¶åŠ è½½å±é™©è·¯å¾„æ¨¡å¼
        config_dangerous = self.config.get('safety', {}).get('dangerous_path_patterns', [])

        # é»˜è®¤å±é™©è·¯å¾„ - åªä¿æŠ¤ç³»ç»Ÿç›®å½•å’Œç”¨æˆ·ä¸»ç›®å½•æœ¬èº«ï¼Œä¸ä¿æŠ¤å­ç›®å½•
        if self.current_os == 'windows':
            dangerous_paths = [
                'c:\\windows', 'c:\\program files', 'c:\\program files (x86)',
                'c:\\system', 'c:\\boot', 'c:\\recovery', 'c:\\'
            ]
            # åªä¿æŠ¤ç”¨æˆ·ä¸»ç›®å½•æœ¬èº«ï¼Œä¸ä¿æŠ¤å­ç›®å½•
            home_str = str(self.home_path).lower()
            if path_str == home_str:
                return True
        elif self.current_os == 'darwin':
            dangerous_paths = [
                '/system', '/usr', '/bin', '/sbin', '/library/system',
                '/boot', '/etc', '/var/root', '/'
            ]
            # åªä¿æŠ¤ç”¨æˆ·ä¸»ç›®å½•æœ¬èº«ï¼Œä¸ä¿æŠ¤å­ç›®å½•
            home_str = str(self.home_path).lower()
            if path_str == home_str:
                return True
        else:  # Linux
            dangerous_paths = [
                '/usr', '/bin', '/sbin', '/boot', '/etc', '/sys', '/proc',
                '/root', '/var/lib', '/opt', '/', '/home'
            ]
            # åªä¿æŠ¤ç”¨æˆ·ä¸»ç›®å½•æœ¬èº«ï¼Œä¸ä¿æŠ¤å­ç›®å½•
            home_str = str(self.home_path).lower()
            if path_str == home_str:
                return True

        # åˆå¹¶é…ç½®æ–‡ä»¶ä¸­çš„å±é™©è·¯å¾„
        dangerous_paths.extend(config_dangerous)

        # æ£€æŸ¥æ˜¯å¦åŒ¹é…å±é™©è·¯å¾„
        for danger in dangerous_paths:
            danger_lower = danger.lower()
            if path_str == danger_lower or path_str.startswith(danger_lower + os.sep):
                return True

        return False

    def _check_write_permission(self, path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å†™æƒé™"""
        try:
            if path.exists():
                return os.access(path, os.W_OK)
            else:
                # æ£€æŸ¥çˆ¶ç›®å½•æƒé™
                parent = path.parent
                return parent.exists() and os.access(parent, os.W_OK)
        except Exception as e:
            logger.warning(f"æƒé™æ£€æŸ¥å¤±è´¥: {path}, {e}")
            return False

    def _require_admin_check(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦ç®¡ç†å‘˜æƒé™"""
        try:
            if self.current_os == 'windows':
                import ctypes
                return ctypes.windll.shell32.IsUserAnAdmin() != 0
            else:
                return os.geteuid() == 0
        except:
            return False
    
    def reinstall_plugin(self, editor_type: str, plugin_id: str = None) -> Dict:
        """é‡æ–°å®‰è£…æ’ä»¶ - å®é™…æ‰§è¡Œç‰ˆæœ¬"""
        print("\nğŸ”„ æ­£åœ¨é‡æ–°å®‰è£…æ’ä»¶...")
        sys.stdout.flush()
        
        logger.info(f"å¼€å§‹é‡æ–°å®‰è£…æ’ä»¶æµç¨‹: {editor_type}")
        
        # å¸¸è§çš„AIä»£ç åŠ©æ‰‹æ’ä»¶ - ä½¿ç”¨æ­£ç¡®çš„å®Œæ•´ID
        target_plugins = [
            'continue.continue',  # Continue AI Assistant (å·²éªŒè¯)
            'tabnine.tabnine-vscode',  # TabNine AI (å·²éªŒè¯)
            'GitHub.copilot',  # GitHub Copilot (æ­£ç¡®æ ¼å¼)
            'Codeium.codeium',  # Codeium AI (æ­£ç¡®æ ¼å¼) 
            'ms-vscode.vscode-typescript-next',  # TypeScriptåŠ©æ‰‹
            # æ³¨æ„ï¼šæŸäº›AIæ’ä»¶å¯èƒ½éœ€è¦ç‰¹å®šæƒé™æˆ–ä¸åœ¨å…¬å…±å¸‚åœº
        ]
        
        if plugin_id:
            target_plugins = [plugin_id]
            print(f"   ğŸ¯ æŒ‡å®šæ’ä»¶: {plugin_id}")
        else:
            print(f"   ğŸ¯ å°è¯•å®‰è£…å¸¸è§AIæ’ä»¶: {len(target_plugins)} ä¸ª")
        
        editor_commands = {
            'vscode': 'code',
            'cursor': 'cursor', 
            'vscodium': 'codium',
            'code-oss': 'code-oss',
            'vscode-insiders': 'code-insiders',
            'theia': 'theia',
            'openvscode': 'openvscode-server',
            'gitpod': 'gitpod'
        }
        
        command = editor_commands.get(editor_type)
        if not command:
            print(f"   âŒ ä¸æ”¯æŒçš„ç¼–è¾‘å™¨ç±»å‹: {editor_type}")
            return {
                'editor_type': editor_type,
                'status': 'error',
                'error': f'ä¸æ”¯æŒçš„ç¼–è¾‘å™¨ç±»å‹: {editor_type}'
            }
        
        print(f"   ğŸ”§ ä½¿ç”¨å‘½ä»¤: {command}")
        
        installed_plugins = []
        failed_plugins = []
        
        for i, plugin in enumerate(target_plugins, 1):
            print(f"   ğŸ“¦ å®‰è£…æ’ä»¶ {i}/{len(target_plugins)}: {plugin}")
            
            try:
                logger.info(f"å°è¯•å®‰è£…æ’ä»¶: {plugin}")
                
                # æ‰§è¡Œæ’ä»¶å®‰è£…å‘½ä»¤
                result = subprocess.run(
                    [command, '--install-extension', plugin],
                    capture_output=True,
                    text=True,
                    timeout=60  # 60ç§’è¶…æ—¶
                )
                
                if result.returncode == 0:
                    print(f"      âœ… å®‰è£…æˆåŠŸ")
                    installed_plugins.append({
                        'plugin_id': plugin,
                        'status': 'success',
                        'output': result.stdout.strip()
                    })
                    logger.info(f"æ’ä»¶ {plugin} å®‰è£…æˆåŠŸ")
                else:
                    print(f"      âŒ å®‰è£…å¤±è´¥: {result.stderr.strip()[:50]}...")
                    failed_plugins.append({
                        'plugin_id': plugin,
                        'status': 'failed',
                        'error': result.stderr.strip()
                    })
                    logger.error(f"æ’ä»¶ {plugin} å®‰è£…å¤±è´¥: {result.stderr}")
                    
            except subprocess.TimeoutExpired:
                print(f"      â° å®‰è£…è¶…æ—¶")
                failed_plugins.append({
                    'plugin_id': plugin,
                    'status': 'timeout',
                    'error': 'å®‰è£…è¶…æ—¶'
                })
                logger.error(f"æ’ä»¶ {plugin} å®‰è£…è¶…æ—¶")
                
            except Exception as e:
                print(f"      âŒ å®‰è£…å¼‚å¸¸: {e}")
                failed_plugins.append({
                    'plugin_id': plugin,
                    'status': 'error', 
                    'error': str(e)
                })
                logger.error(f"æ’ä»¶ {plugin} å®‰è£…å¼‚å¸¸: {e}")
        
        print(f"   âœ… æ’ä»¶å®‰è£…å®Œæˆï¼æˆåŠŸ: {len(installed_plugins)}, å¤±è´¥: {len(failed_plugins)}")
        
        result = {
            'editor_type': editor_type,
            'action': 'reinstall_plugin',
            'status': 'completed',
            'installed_plugins': installed_plugins,
            'failed_plugins': failed_plugins,
            'total_attempted': len(target_plugins),
            'total_installed': len(installed_plugins),
            'total_failed': len(failed_plugins),
            'message': f'æ’ä»¶å®‰è£…å®Œæˆã€‚æˆåŠŸ: {len(installed_plugins)}, å¤±è´¥: {len(failed_plugins)}'
        }
        
        logger.info(f"æ’ä»¶é‡å®‰è£…æµç¨‹å®Œæˆ: æˆåŠŸ{len(installed_plugins)}ä¸ª, å¤±è´¥{len(failed_plugins)}ä¸ª")
        return result
    
    def uninstall_plugin(self, editor_type: str, plugin_id: str = None) -> Dict:
        """å¸è½½æ’ä»¶"""
        logger.info(f"å¼€å§‹å¸è½½æ’ä»¶æµç¨‹: {editor_type}")
        
        # é»˜è®¤çš„AIä»£ç åŠ©æ‰‹æ’ä»¶åˆ—è¡¨ - ä¸å®‰è£…åˆ—è¡¨ä¿æŒä¸€è‡´
        target_plugins = [
            'continue.continue',  # Continue AI Assistant (å·²éªŒè¯)
            'tabnine.tabnine-vscode',  # TabNine AI (å·²éªŒè¯)
            'GitHub.copilot',  # GitHub Copilot (æ­£ç¡®æ ¼å¼)
            'Codeium.codeium',  # Codeium AI (æ­£ç¡®æ ¼å¼)
            'ms-vscode.vscode-typescript-next',  # TypeScriptåŠ©æ‰‹
        ]
        
        if plugin_id:
            target_plugins = [plugin_id]
        
        editor_commands = {
            'vscode': 'code',
            'cursor': 'cursor', 
            'vscodium': 'codium',
            'code-oss': 'code-oss',
            'vscode-insiders': 'code-insiders',
            'theia': 'theia',
            'openvscode': 'openvscode-server',
            'gitpod': 'gitpod'
        }
        
        command = editor_commands.get(editor_type)
        if not command:
            return {
                'editor_type': editor_type,
                'status': 'error',
                'error': f'ä¸æ”¯æŒçš„ç¼–è¾‘å™¨ç±»å‹: {editor_type}'
            }
        
        uninstalled_plugins = []
        failed_plugins = []
        
        for plugin in target_plugins:
            try:
                logger.info(f"å°è¯•å¸è½½æ’ä»¶: {plugin}")
                
                # æ‰§è¡Œæ’ä»¶å¸è½½å‘½ä»¤
                result = subprocess.run(
                    [command, '--uninstall-extension', plugin],
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                
                if result.returncode == 0:
                    uninstalled_plugins.append({
                        'plugin_id': plugin,
                        'status': 'success',
                        'output': result.stdout.strip()
                    })
                    logger.info(f"æ’ä»¶ {plugin} å¸è½½æˆåŠŸ")
                else:
                    failed_plugins.append({
                        'plugin_id': plugin,
                        'status': 'failed',
                        'error': result.stderr.strip()
                    })
                    logger.error(f"æ’ä»¶ {plugin} å¸è½½å¤±è´¥: {result.stderr}")
                    
            except subprocess.TimeoutExpired:
                failed_plugins.append({
                    'plugin_id': plugin,
                    'status': 'timeout',
                    'error': 'å¸è½½è¶…æ—¶'
                })
                logger.error(f"æ’ä»¶ {plugin} å¸è½½è¶…æ—¶")
                
            except Exception as e:
                failed_plugins.append({
                    'plugin_id': plugin,
                    'status': 'error', 
                    'error': str(e)
                })
                logger.error(f"æ’ä»¶ {plugin} å¸è½½å¼‚å¸¸: {e}")
        
        result = {
            'editor_type': editor_type,
            'action': 'uninstall_plugin',
            'status': 'completed',
            'uninstalled_plugins': uninstalled_plugins,
            'failed_plugins': failed_plugins,
            'total_attempted': len(target_plugins),
            'total_uninstalled': len(uninstalled_plugins),
            'total_failed': len(failed_plugins),
            'message': f'æ’ä»¶å¸è½½å®Œæˆã€‚æˆåŠŸ: {len(uninstalled_plugins)}, å¤±è´¥: {len(failed_plugins)}'
        }
        
        logger.info(f"æ’ä»¶å¸è½½æµç¨‹å®Œæˆ: æˆåŠŸ{len(uninstalled_plugins)}ä¸ª, å¤±è´¥{len(failed_plugins)}ä¸ª")
        return result
    
    def list_installed_extensions(self, editor_type: str) -> Dict:
        """åˆ—å‡ºå·²å®‰è£…çš„æ‰©å±•"""
        logger.info(f"è·å–å·²å®‰è£…æ‰©å±•åˆ—è¡¨: {editor_type}")
        
        editor_commands = {
            'vscode': 'code',
            'cursor': 'cursor', 
            'vscodium': 'codium',
            'code-oss': 'code-oss',
            'vscode-insiders': 'code-insiders',
            'theia': 'theia',
            'openvscode': 'openvscode-server',
            'gitpod': 'gitpod'
        }
        
        command = editor_commands.get(editor_type)
        if not command:
            return {
                'editor_type': editor_type,
                'status': 'error',
                'error': f'ä¸æ”¯æŒçš„ç¼–è¾‘å™¨ç±»å‹: {editor_type}'
            }
        
        try:
            result = subprocess.run(
                [command, '--list-extensions'],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                extensions = result.stdout.strip().split('\n') if result.stdout.strip() else []
                extensions = [ext.strip() for ext in extensions if ext.strip()]
                
                # è¿‡æ»¤å‡ºå¯èƒ½ç›¸å…³çš„æ’ä»¶
                relevant_extensions = []
                augment_related = []
                
                for ext in extensions:
                    if any(keyword in ext.lower() for keyword in ['augment', 'ai', 'copilot', 'codeium', 'tabnine', 'continue']):
                        augment_related.append(ext)
                    relevant_extensions.append(ext)
                
                return {
                    'editor_type': editor_type,
                    'status': 'success',
                    'total_extensions': len(extensions),
                    'all_extensions': extensions,
                    'augment_related_extensions': augment_related,
                    'message': f'æ‰¾åˆ° {len(extensions)} ä¸ªå·²å®‰è£…æ‰©å±•ï¼Œå…¶ä¸­ {len(augment_related)} ä¸ªå¯èƒ½ç›¸å…³'
                }
            else:
                return {
                    'editor_type': editor_type,
                    'status': 'error',
                    'error': result.stderr.strip() or 'è·å–æ‰©å±•åˆ—è¡¨å¤±è´¥'
                }
                
        except subprocess.TimeoutExpired:
            return {
                'editor_type': editor_type,
                'status': 'timeout',
                'error': 'è·å–æ‰©å±•åˆ—è¡¨è¶…æ—¶'
            }
        except Exception as e:
            return {
                'editor_type': editor_type,
                'status': 'error',
                'error': str(e)
            }
    
    def install_vsix_plugin(self, editor_type: str, vsix_path: str = None) -> Dict:
        """å®‰è£…VSIXæ’ä»¶æ–‡ä»¶"""
        logger.info(f"å¼€å§‹å®‰è£…VSIXæ’ä»¶: {editor_type}")
        
        # é»˜è®¤çš„å†…ç½®VSIXæ–‡ä»¶è·¯å¾„
        default_vsix = "augment-plugin-embedded.vsix"
        vsix_file = vsix_path if vsix_path else default_vsix
        
        # æ£€æŸ¥VSIXæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(vsix_file).exists():
            return {
                'editor_type': editor_type,
                'status': 'error',
                'error': f'VSIXæ–‡ä»¶ä¸å­˜åœ¨: {vsix_file}'
            }
        
        editor_commands = {
            'vscode': 'code',
            'cursor': 'cursor', 
            'vscodium': 'codium',
            'code-oss': 'code-oss',
            'vscode-insiders': 'code-insiders',
            'theia': 'theia',
            'openvscode': 'openvscode-server',
            'gitpod': 'gitpod'
        }
        
        command = editor_commands.get(editor_type)
        if not command:
            return {
                'editor_type': editor_type,
                'status': 'error',
                'error': f'ä¸æ”¯æŒçš„ç¼–è¾‘å™¨ç±»å‹: {editor_type}'
            }
        
        try:
            logger.info(f"å®‰è£…VSIXæ–‡ä»¶: {vsix_file}")
            
            result = subprocess.run(
                [command, '--install-extension', vsix_file],
                capture_output=True,
                text=True,
                timeout=60
            )
            
            if result.returncode == 0:
                return {
                    'editor_type': editor_type,
                    'status': 'success',
                    'vsix_file': vsix_file,
                    'output': result.stdout.strip(),
                    'message': f'VSIXæ’ä»¶å®‰è£…æˆåŠŸ: {vsix_file}'
                }
            else:
                return {
                    'editor_type': editor_type,
                    'status': 'failed',
                    'vsix_file': vsix_file,
                    'error': result.stderr.strip(),
                    'message': f'VSIXæ’ä»¶å®‰è£…å¤±è´¥: {vsix_file}'
                }
                
        except subprocess.TimeoutExpired:
            return {
                'editor_type': editor_type,
                'status': 'timeout',
                'vsix_file': vsix_file,
                'error': 'VSIXå®‰è£…è¶…æ—¶'
            }
        except Exception as e:
            return {
                'editor_type': editor_type,
                'status': 'error',
                'vsix_file': vsix_file,
                'error': str(e)
            }
    
    def force_exit_app(self, editor_type: str) -> Dict:
        """å¼ºåˆ¶é€€å‡ºåº”ç”¨ç¨‹åº"""
        logger.info(f"å¼ºåˆ¶é€€å‡ºåº”ç”¨ç¨‹åº: {editor_type}")
        
        app_names = {
            'vscode': ['Visual Studio Code', 'Code'],
            'cursor': ['Cursor'], 
            'vscodium': ['VSCodium'],
            'code-oss': ['Code - OSS'],
            'vscode-insiders': ['Visual Studio Code - Insiders'],
            'theia': ['Theia'],
            'openvscode': ['OpenVSCode Server'],
            'gitpod': ['Gitpod']
        }
        
        names = app_names.get(editor_type, [])
        if not names:
            return {
                'editor_type': editor_type,
                'status': 'error',
                'error': f'ä¸æ”¯æŒçš„ç¼–è¾‘å™¨ç±»å‹: {editor_type}'
            }
        
        killed_processes = []
        failed_processes = []
        
        for app_name in names:
            try:
                # æ ¹æ®æ“ä½œç³»ç»Ÿå¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹
                if self.current_os == 'windows':
                    # Windows: å¼ºåˆ¶ç»ˆæ­¢
                    result = subprocess.run(
                        ['taskkill', '/F', '/IM', f'{app_name}.exe'],
                        capture_output=True,
                        text=True
                    )
                elif self.current_os == 'darwin':
                    # macOS: å¼ºåˆ¶æ€æ­»
                    result = subprocess.run(
                        ['killall', '-9', app_name],
                        capture_output=True,
                        text=True
                    )
                else:
                    # Linux: å¼ºåˆ¶æ€æ­»
                    result = subprocess.run(
                        ['pkill', '-9', '-f', app_name],
                        capture_output=True,
                        text=True
                    )
                
                if result.returncode == 0:
                    killed_processes.append(app_name)
                    logger.info(f"æˆåŠŸç»ˆæ­¢è¿›ç¨‹: {app_name}")
                else:
                    # è¿›ç¨‹ä¸å­˜åœ¨ä¹Ÿç®—æ­£å¸¸
                    if "No matching processes" in result.stderr:
                        killed_processes.append(f"{app_name} (æœªè¿è¡Œ)")
                    else:
                        failed_processes.append({
                            'app_name': app_name,
                            'error': result.stderr.strip()
                        })
                        
            except Exception as e:
                failed_processes.append({
                    'app_name': app_name,
                    'error': str(e)
                })
                logger.error(f"ç»ˆæ­¢è¿›ç¨‹ {app_name} æ—¶å‡ºé”™: {e}")
        
        return {
            'editor_type': editor_type,
            'status': 'completed',
            'killed_processes': killed_processes,
            'failed_processes': failed_processes,
            'message': f'è¿›ç¨‹ç»ˆæ­¢å®Œæˆã€‚æˆåŠŸ: {len(killed_processes)}, å¤±è´¥: {len(failed_processes)}'
        }
    
    def shell_execute(self, command: str, timeout: int = 30) -> Dict:
        """æ‰§è¡Œç³»ç»Ÿå‘½ä»¤"""
        logger.info(f"æ‰§è¡Œç³»ç»Ÿå‘½ä»¤: {command}")
        
        try:
            result = subprocess.run(
                command,
                shell=True,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            
            return {
                'command': command,
                'status': 'completed',
                'returncode': result.returncode,
                'stdout': result.stdout,
                'stderr': result.stderr,
                'success': result.returncode == 0
            }
            
        except subprocess.TimeoutExpired:
            return {
                'command': command,
                'status': 'timeout',
                'error': f'å‘½ä»¤æ‰§è¡Œè¶…æ—¶ ({timeout}ç§’)'
            }
        except Exception as e:
            return {
                'command': command,
                'status': 'error',
                'error': str(e)
            }
    
    def get_supported_operations(self) -> List[str]:
        """è·å–æ”¯æŒçš„æ“ä½œåˆ—è¡¨"""
        return [
            'modify_telemetry_ids',
            'clean_database', 
            'clean_workspace',
            'clear_chat_history',
            'clean_extension_cache',
            'clean_logs_and_crashes',
            'clean_browser_cache',
            'clean_user_settings',
            'clean_network_cache',
            'clean_temporary_files',
            'clean_augment_deep',
            'clean_analytics_data',
            'clean_vscode_cdn_cache',
            'reinstall_plugin',
            'uninstall_plugin',
            'list_installed_extensions',
            'install_vsix_plugin',
            'force_exit_app',
            'shell_execute',
            'kill_editor_processes'
        ]
    
    # æ–‡ä»¶ç³»ç»Ÿæ“ä½œåŠŸèƒ½
    def open_path(self, path: str) -> Dict:
        """æ‰“å¼€æ–‡ä»¶è·¯å¾„"""
        try:
            path_obj = Path(path).expanduser().resolve()
            
            if path_obj.exists():
                # æ ¹æ®æ“ä½œç³»ç»Ÿé€‰æ‹©æ‰“å¼€å‘½ä»¤
                if self.current_os == 'windows':
                    result = subprocess.run(['start', str(path_obj)], shell=True,
                                           capture_output=True, text=True)
                elif self.current_os == 'darwin':
                    result = subprocess.run(['open', str(path_obj)], 
                                           capture_output=True, text=True)
                else:  # Linux
                    result = subprocess.run(['xdg-open', str(path_obj)], 
                                           capture_output=True, text=True)
                
                if result.returncode == 0:
                    return {
                        'path': str(path_obj),
                        'status': 'success',
                        'message': f'æˆåŠŸæ‰“å¼€è·¯å¾„: {path_obj}'
                    }
                else:
                    return {
                        'path': str(path_obj),
                        'status': 'failed',
                        'error': result.stderr.strip()
                    }
            else:
                return {
                    'path': str(path_obj),
                    'status': 'not_found',
                    'error': 'è·¯å¾„ä¸å­˜åœ¨'
                }
                
        except Exception as e:
            return {
                'path': path,
                'status': 'error',
                'error': str(e)
            }
    
    def exists(self, path: str) -> Dict:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        try:
            path_obj = Path(path).expanduser().resolve()
            
            return {
                'path': str(path_obj),
                'exists': path_obj.exists(),
                'is_file': path_obj.is_file() if path_obj.exists() else False,
                'is_directory': path_obj.is_dir() if path_obj.exists() else False,
                'size': path_obj.stat().st_size if path_obj.exists() and path_obj.is_file() else None
            }
            
        except Exception as e:
            return {
                'path': path,
                'error': str(e),
                'exists': False
            }
    
    def read_dir(self, path: str, pattern: str = "*") -> Dict:
        """è¯»å–ç›®å½•å†…å®¹"""
        try:
            path_obj = Path(path).expanduser().resolve()
            
            if not path_obj.exists():
                return {
                    'path': str(path_obj),
                    'status': 'not_found',
                    'error': 'ç›®å½•ä¸å­˜åœ¨'
                }
            
            if not path_obj.is_dir():
                return {
                    'path': str(path_obj),
                    'status': 'not_directory',
                    'error': 'è·¯å¾„ä¸æ˜¯ç›®å½•'
                }
            
            # ä½¿ç”¨globæ¨¡å¼åŒ¹é…æ–‡ä»¶
            files = []
            directories = []
            
            for item in path_obj.glob(pattern):
                item_info = {
                    'name': item.name,
                    'path': str(item),
                    'size': item.stat().st_size if item.is_file() else None,
                    'modified': item.stat().st_mtime
                }
                
                if item.is_file():
                    files.append(item_info)
                elif item.is_dir():
                    directories.append(item_info)
            
            return {
                'path': str(path_obj),
                'status': 'success',
                'pattern': pattern,
                'files': files,
                'directories': directories,
                'total_files': len(files),
                'total_directories': len(directories)
            }
            
        except Exception as e:
            return {
                'path': path,
                'status': 'error',
                'error': str(e)
            }
    
    def copy_file(self, source: str, destination: str) -> Dict:
        """æ–‡ä»¶å¤åˆ¶æ“ä½œ"""
        try:
            source_path = Path(source).expanduser().resolve()
            dest_path = Path(destination).expanduser().resolve()
            
            if not source_path.exists():
                return {
                    'source': str(source_path),
                    'destination': str(dest_path),
                    'status': 'source_not_found',
                    'error': 'æºæ–‡ä»¶ä¸å­˜åœ¨'
                }
            
            # å¦‚æœç›®æ ‡æ˜¯ç›®å½•ï¼Œåˆ™åœ¨ç›®å½•ä¸­åˆ›å»ºåŒåæ–‡ä»¶
            if dest_path.exists() and dest_path.is_dir():
                dest_path = dest_path / source_path.name
            
            # åˆ›å»ºç›®æ ‡ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            dest_path.parent.mkdir(parents=True, exist_ok=True)
            
            if source_path.is_file():
                shutil.copy2(source_path, dest_path)
            elif source_path.is_dir():
                shutil.copytree(source_path, dest_path, dirs_exist_ok=True)
            
            return {
                'source': str(source_path),
                'destination': str(dest_path),
                'status': 'success',
                'message': f'æˆåŠŸå¤åˆ¶: {source_path.name}'
            }
            
        except Exception as e:
            return {
                'source': source,
                'destination': destination,
                'status': 'error',
                'error': str(e)
            }
    
    def remove(self, path: str, force: bool = False) -> Dict:
        """æ–‡ä»¶åˆ é™¤æ“ä½œ"""
        try:
            path_obj = Path(path).expanduser().resolve()
            
            if not path_obj.exists():
                return {
                    'path': str(path_obj),
                    'status': 'not_found',
                    'error': 'æ–‡ä»¶æˆ–ç›®å½•ä¸å­˜åœ¨'
                }
            
            # å®‰å…¨æ£€æŸ¥ - é¿å…åˆ é™¤é‡è¦ç³»ç»Ÿç›®å½•
            dangerous_paths = ['/usr', '/bin', '/sbin', '/boot', '/etc', '/sys', '/proc']
            if any(str(path_obj).startswith(danger) for danger in dangerous_paths):
                return {
                    'path': str(path_obj),
                    'status': 'forbidden',
                    'error': 'ä¸å…è®¸åˆ é™¤ç³»ç»Ÿç›®å½•'
                }
            
            if path_obj.is_file():
                path_obj.unlink()
                return {
                    'path': str(path_obj),
                    'status': 'success',
                    'type': 'file',
                    'message': f'æˆåŠŸåˆ é™¤æ–‡ä»¶: {path_obj.name}'
                }
            elif path_obj.is_dir():
                if force:
                    shutil.rmtree(path_obj)
                    return {
                        'path': str(path_obj),
                        'status': 'success',
                        'type': 'directory',
                        'message': f'æˆåŠŸåˆ é™¤ç›®å½•: {path_obj.name}'
                    }
                else:
                    # æ£€æŸ¥ç›®å½•æ˜¯å¦ä¸ºç©º
                    if any(path_obj.iterdir()):
                        return {
                            'path': str(path_obj),
                            'status': 'not_empty',
                            'error': 'ç›®å½•ä¸ä¸ºç©ºï¼Œä½¿ç”¨ force=True å¼ºåˆ¶åˆ é™¤'
                        }
                    else:
                        path_obj.rmdir()
                        return {
                            'path': str(path_obj),
                            'status': 'success',
                            'type': 'directory',
                            'message': f'æˆåŠŸåˆ é™¤ç©ºç›®å½•: {path_obj.name}'
                        }
            
        except Exception as e:
            return {
                'path': path,
                'status': 'error',
                'error': str(e)
            }
    
    def run_all_operations(self, editor_type: str) -> Dict:
        """è¿è¡Œæ‰€æœ‰æ¸…ç†æ“ä½œ"""
        print("\n" + "="*60)
        print("ğŸš€ å¼€å§‹æ‰§è¡Œå®Œæ•´æ¸…ç†æ“ä½œæµç¨‹")
        print("="*60)
        print(f"ğŸ“± ç›®æ ‡ç¼–è¾‘å™¨: {self.EDITORS.get(editor_type, editor_type)}")
        sys.stdout.flush()
        
        logger.info(f"å¼€å§‹æ‰§è¡Œå®Œæ•´æ¸…ç†æ“ä½œ: {editor_type}")
        
        # é¦–å…ˆç»“æŸç¼–è¾‘å™¨è¿›ç¨‹
        print("\nğŸ›‘ ç¬¬0æ­¥: ç»“æŸç¼–è¾‘å™¨è¿›ç¨‹...")
        self.kill_editor_processes(editor_type)
        
        results = {
            'editor_type': editor_type,
            'operations': {}
        }
        
        operations = [
            ('modify_telemetry_ids', 'ğŸ†” ç¬¬1æ­¥: ä¿®æ”¹é¥æµ‹ID', self.modify_telemetry_ids),
            ('clean_database', 'ğŸ—„ï¸  ç¬¬2æ­¥: æ¸…ç†æ•°æ®åº“', self.clean_database),
            ('clean_workspace', 'ğŸ“ ç¬¬3æ­¥: æ¸…ç†å·¥ä½œåŒº', self.clean_workspace),
            ('clear_chat_history', 'ğŸ’¬ ç¬¬4æ­¥: æ¸…ç†èŠå¤©å†å²', self.clear_chat_history),
            ('clean_extension_cache', 'ğŸ—‚ï¸  ç¬¬5æ­¥: æ¸…ç†æ‰©å±•ç¼“å­˜', self.clean_extension_cache),
            ('clean_logs_and_crashes', 'ğŸ“‹ ç¬¬6æ­¥: æ¸…ç†æ—¥å¿—å´©æºƒ', self.clean_logs_and_crashes),
            ('clean_browser_cache', 'ğŸŒ ç¬¬7æ­¥: æ¸…ç†æµè§ˆå™¨ç¼“å­˜', self.clean_browser_cache),
            ('clean_user_settings', 'âš™ï¸  ç¬¬8æ­¥: æ¸…ç†ç”¨æˆ·è®¾ç½®', self.clean_user_settings),
            ('clean_network_cache', 'ğŸŒ ç¬¬9æ­¥: æ¸…ç†ç½‘ç»œç¼“å­˜', self.clean_network_cache),
            ('clean_temporary_files', 'ğŸ—‘ï¸  ç¬¬10æ­¥: æ¸…ç†ä¸´æ—¶æ–‡ä»¶', self.clean_temporary_files),
            ('clean_vscode_cdn_cache', 'ğŸ“¦ ç¬¬11æ­¥: æ¸…ç†CDNç¼“å­˜', self.clean_vscode_cdn_cache),
            ('clean_augment_deep', 'ğŸš€ ç¬¬12æ­¥: Augmentæ·±åº¦æ¸…ç†', self.clean_augment_deep),
            ('clean_analytics_data', 'ğŸ“Š ç¬¬13æ­¥: åˆ†ææ•°æ®æ¸…ç†', self.clean_analytics_data),
            ('reinstall_plugin', 'ğŸ”Œ ç¬¬14æ­¥: é‡æ–°å®‰è£…æ’ä»¶', self.reinstall_plugin)
        ]
        
        try:
            for i, (op_key, op_desc, op_func) in enumerate(operations, 1):
                print(f"\n{op_desc}")
                print(f"   è¿›åº¦: {i}/{len(operations)}")
                
                try:
                    results['operations'][op_key] = op_func(editor_type)
                    print(f"   âœ… {op_desc.split(':')[1].strip()} å®Œæˆ")
                except Exception as e:
                    print(f"   âŒ {op_desc.split(':')[1].strip()} å¤±è´¥: {e}")
                    results['operations'][op_key] = {
                        'status': 'error',
                        'error': str(e)
                    }
            
            results['status'] = 'success'
            results['message'] = 'æ‰€æœ‰æ“ä½œæ‰§è¡Œå®Œæˆ'
            
            print(f"\nğŸ‰ æ‰€æœ‰æ“ä½œæ‰§è¡Œå®Œæˆï¼")
            print("="*60)
            
        except Exception as e:
            results['status'] = 'error'
            results['error'] = str(e)
            print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹å‡ºç°é”™è¯¯: {e}")
            logger.error(f"æ‰§è¡Œæ“ä½œæ—¶å‡ºé”™: {e}")
        
        return results
    
    def run_all_operations_command(self, editor_type: str) -> Dict:
        """å®Œæ•´çš„æ“ä½œå‘½ä»¤"""
        logger.info(f"å¼€å§‹æ‰§è¡Œå®Œæ•´æ“ä½œåºåˆ—: {editor_type}")
        
        # 1. è·å–ç³»ç»Ÿä¿¡æ¯
        system_info = self.get_system_info()
        
        # 2. æ‰§è¡Œæ‰€æœ‰æ“ä½œ
        operations_result = self.run_all_operations(editor_type)
        
        # 3. éªŒè¯ä¸å®Œæˆ
        verification_result = self.verify_operations_result(operations_result)
        
        # 4. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        final_result = {
            'system_info': system_info,
            'operations_result': operations_result,
            'verification': verification_result,
            'recovery_options': {
                'storage_backup': 'storage.json.bak æ–‡ä»¶å¯ç”¨äºæ¢å¤é…ç½®',
                'machine_id_backup': 'machine_id_backup.json åŒ…å«åŸå§‹IDä¿¡æ¯',
                'operation_log': 'è¯¦ç»†æ“ä½œæ—¥å¿—å·²è®°å½•'
            }
        }
        
        # 5. ç”Ÿæˆå¹¶æ‰“å°è¯¦ç»†æŠ¥å‘Š
        detailed_report = self.generate_operation_report(final_result)
        logger.info("ç”Ÿæˆè¯¦ç»†æ“ä½œæŠ¥å‘Š")
        print(detailed_report)
        
        return final_result
    
    def verify_operations_result(self, operations_result: Dict) -> Dict:
        """éªŒè¯æ“ä½œç»“æœ"""
        verification = {
            'overall_status': operations_result.get('status', 'unknown'),
            'operations_completed': len(operations_result.get('operations', {})),
            'issues_found': [],
            'recommendations': []
        }
        
        # æ£€æŸ¥å„ä¸ªæ“ä½œçš„ç»“æœ
        operations = operations_result.get('operations', {})
        
        if 'modify_telemetry_ids' in operations:
            telemetry_result = operations['modify_telemetry_ids']
            if telemetry_result.get('backup_created'):
                verification['recommendations'].append('é¥æµ‹IDå·²æˆåŠŸä¿®æ”¹ï¼Œå¤‡ä»½æ–‡ä»¶å·²åˆ›å»º')
            
        if 'clean_database' in operations:
            db_result = operations['clean_database']
            deleted_rows = db_result.get('deleted_rows', 0)
            if deleted_rows > 0:
                verification['recommendations'].append(f'æ•°æ®åº“æ¸…ç†æˆåŠŸï¼Œåˆ é™¤äº† {deleted_rows} è¡Œæ•°æ®')
            else:
                verification['issues_found'].append('æ•°æ®åº“ä¸­æœªæ‰¾åˆ°éœ€è¦æ¸…ç†çš„æ•°æ®')
        
        if 'clean_workspace' in operations:
            workspace_result = operations['clean_workspace']
            deleted_files = workspace_result.get('deleted_files', 0)
            if deleted_files > 0:
                verification['recommendations'].append(f'å·¥ä½œåŒºæ¸…ç†æˆåŠŸï¼Œåˆ é™¤äº† {deleted_files} ä¸ªæ–‡ä»¶')
        
        # æ£€æŸ¥æ–°å¢çš„æ·±åº¦æ¸…æ´—åŠŸèƒ½
        deep_clean_ops = ['clean_extension_cache', 'clean_logs_and_crashes', 'clean_browser_cache', 
                         'clean_user_settings', 'clean_network_cache', 'clean_temporary_files',
                         'clean_vscode_cdn_cache', 'clean_augment_deep', 'clean_analytics_data']
        
        for op_name in deep_clean_ops:
            if op_name in operations:
                result = operations[op_name]
                deleted = result.get('deleted_files', 0) or result.get('cleaned_items', 0) or result.get('cleaned_database_rows', 0)
                if deleted > 0:
                    op_display = op_name.replace('_', ' ').title()
                    verification['recommendations'].append(f'{op_display}æˆåŠŸï¼Œæ¸…ç†äº† {deleted} é¡¹')
        
        verification['message'] = 'æ“ä½œéªŒè¯å®Œæˆ'
        return verification
    
    def generate_operation_report(self, final_result: Dict) -> str:
        """ç”Ÿæˆè¯¦ç»†çš„æ“ä½œæŠ¥å‘Š"""
        report_lines = []
        report_lines.append("=" * 60)
        report_lines.append("ğŸ“Š VS Code é¥æµ‹ç®¡ç†å™¨ - æ“ä½œæŠ¥å‘Š")
        report_lines.append("=" * 60)
        
        # ç³»ç»Ÿä¿¡æ¯éƒ¨åˆ†
        system_info = final_result.get('system_info', {})
        report_lines.append("\nğŸ–¥ï¸  ç³»ç»Ÿä¿¡æ¯:")
        report_lines.append(f"   å¹³å°: {system_info.get('platform', 'unknown')}")
        report_lines.append(f"   å¯ç”¨ç¼–è¾‘å™¨: {len(system_info.get('available_editors', []))} ä¸ª")
        
        # æ“ä½œç»“æœéƒ¨åˆ†
        operations_result = final_result.get('operations_result', {})
        verification = final_result.get('verification', {})
        
        report_lines.append(f"\nğŸ“‹ æ€»ä½“çŠ¶æ€: {operations_result.get('status', 'unknown').upper()}")
        report_lines.append(f"ğŸ“ å®Œæˆæ“ä½œæ•°: {verification.get('operations_completed', 0)}")
        
        # è¯¦ç»†æ“ä½œç»“æœ
        operations = operations_result.get('operations', {})
        
        if operations:
            report_lines.append("\nğŸ”§ æ“ä½œè¯¦æƒ…:")
            
            # 1. é¥æµ‹IDä¿®æ”¹
            if 'modify_telemetry_ids' in operations:
                telemetry = operations['modify_telemetry_ids']
                report_lines.append("\n   âœ… é¥æµ‹IDä¿®æ”¹:")
                report_lines.append(f"      åŸmachineId: {telemetry.get('old_machine_id', 'N/A')[:8]}...")
                report_lines.append(f"      æ–°machineId: {telemetry.get('new_machine_id', 'N/A')[:8]}...")
                report_lines.append(f"      å¤‡ä»½æ–‡ä»¶: {telemetry.get('backup_created', 'N/A')}")
            
            # 2. æ•°æ®åº“æ¸…ç†
            if 'clean_database' in operations:
                db_result = operations['clean_database']
                deleted_rows = db_result.get('deleted_rows', 0)
                status_icon = "âœ…" if deleted_rows > 0 else "âš ï¸"
                report_lines.append(f"\n   {status_icon} æ•°æ®åº“æ¸…ç†:")
                report_lines.append(f"      åˆ é™¤è¡Œæ•°: {deleted_rows}")
                report_lines.append(f"      å¤„ç†æ•°æ®åº“: {len(db_result.get('processed_databases', []))}")
                
                if deleted_rows == 0:
                    report_lines.append("      æ³¨æ„: æœªæ‰¾åˆ°éœ€è¦æ¸…ç†çš„augmentæ•°æ®")
            
            # 3. å·¥ä½œåŒºæ¸…ç†
            if 'clean_workspace' in operations:
                workspace = operations['clean_workspace']
                deleted_files = workspace.get('deleted_files', 0)
                status_icon = "âœ…" if deleted_files > 0 else "âš ï¸"
                report_lines.append(f"\n   {status_icon} å·¥ä½œåŒºæ¸…ç†:")
                report_lines.append(f"      åˆ é™¤æ–‡ä»¶: {deleted_files}")
                report_lines.append(f"      å¤„ç†ç›®å½•: {len(workspace.get('processed_directories', []))}")
            
            # 4. èŠå¤©å†å²æ¸…ç†
            if 'clear_chat_history' in operations:
                chat = operations['clear_chat_history']
                deleted_files = chat.get('deleted_files', 0)
                status_icon = "âœ…" if deleted_files > 0 else "âš ï¸"
                report_lines.append(f"\n   {status_icon} èŠå¤©å†å²æ¸…ç†:")
                report_lines.append(f"      åˆ é™¤æ–‡ä»¶: {deleted_files}")
                report_lines.append(f"      å¤„ç†è·¯å¾„: {len(chat.get('processed_paths', []))}")
            
            # 5. æ’ä»¶é‡å®‰è£…
            if 'reinstall_plugin' in operations:
                plugin = operations['reinstall_plugin']
                installed = plugin.get('total_installed', 0)
                failed = plugin.get('total_failed', 0)
                status_icon = "âœ…" if installed > 0 else "âŒ" if failed > 0 else "âš ï¸"
                report_lines.append(f"\n   {status_icon} æ’ä»¶é‡å®‰è£…:")
                report_lines.append(f"      æˆåŠŸå®‰è£…: {installed}")
                report_lines.append(f"      å®‰è£…å¤±è´¥: {failed}")
                
                if plugin.get('installed_plugins'):
                    report_lines.append("      æˆåŠŸæ’ä»¶:")
                    for p in plugin.get('installed_plugins', [])[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                        report_lines.append(f"        - {p.get('plugin_id', 'unknown')}")
        
        # éªŒè¯ç»“æœéƒ¨åˆ†
        if verification.get('recommendations'):
            report_lines.append("\nâœ… æˆåŠŸé¡¹ç›®:")
            for rec in verification['recommendations']:
                report_lines.append(f"   â€¢ {rec}")
        
        if verification.get('issues_found'):
            report_lines.append("\nâš ï¸  æ³¨æ„äº‹é¡¹:")
            for issue in verification['issues_found']:
                report_lines.append(f"   â€¢ {issue}")
        
        # æ¢å¤é€‰é¡¹
        recovery = final_result.get('recovery_options', {})
        if recovery:
            report_lines.append("\nğŸ”„ æ¢å¤é€‰é¡¹:")
            for key, value in recovery.items():
                report_lines.append(f"   â€¢ {value}")
        
        # æ“ä½œå»ºè®®
        report_lines.append("\nğŸ’¡ æ“ä½œå»ºè®®:")
        total_changes = 0
        if operations:
            total_changes += operations.get('clean_database', {}).get('deleted_rows', 0)
            total_changes += operations.get('clean_workspace', {}).get('deleted_files', 0)
            total_changes += operations.get('clear_chat_history', {}).get('deleted_files', 0)
        
        if total_changes > 0:
            report_lines.append("   â€¢ å»ºè®®é‡å¯ç¼–è¾‘å™¨ä»¥ç¡®ä¿æ›´æ”¹ç”Ÿæ•ˆ")
            report_lines.append("   â€¢ å¦‚æœ‰é—®é¢˜ï¼Œå¯ä½¿ç”¨å¤‡ä»½æ–‡ä»¶æ¢å¤")
        else:
            report_lines.append("   â€¢ ç³»ç»Ÿä¸­æœªå‘ç°éœ€è¦æ¸…ç†çš„æ•°æ®")
            report_lines.append("   â€¢ å¯èƒ½AugmentCodeæ’ä»¶æœªå®‰è£…æˆ–å·²æ¸…ç†")
        
        report_lines.append("\n" + "=" * 60)
        report_lines.append(f"ğŸ“… æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {uuid.uuid4().hex[:8]}")  # ç®€å•çš„æ—¶é—´æ ‡è¯†
        report_lines.append("=" * 60)
        
        return "\n".join(report_lines)
    
    def generate_simple_report(self, operations_result: Dict) -> str:
        """ç”Ÿæˆç®€åŒ–çš„æ“ä½œæŠ¥å‘Š"""
        report_lines = []
        report_lines.append("\n" + "="*40)
        report_lines.append("ğŸ“Š æ“ä½œæ€»ç»“")
        report_lines.append("="*40)
        
        operations = operations_result.get('operations', {})
        total_success = 0
        total_items = 0
        
        for op_name, op_result in operations.items():
            if op_name == 'modify_telemetry_ids':
                if op_result.get('backup_created'):
                    report_lines.append("âœ… é¥æµ‹IDä¿®æ”¹ - æˆåŠŸ")
                    total_success += 1
                else:
                    report_lines.append("âŒ é¥æµ‹IDä¿®æ”¹ - å¤±è´¥")
                total_items += 1
                
            elif op_name == 'clean_database':
                deleted = op_result.get('deleted_rows', 0)
                if deleted > 0:
                    report_lines.append(f"âœ… æ•°æ®åº“æ¸…ç† - åˆ é™¤{deleted}è¡Œ")
                    total_success += 1
                else:
                    report_lines.append("âš ï¸  æ•°æ®åº“æ¸…ç† - æ— æ•°æ®éœ€æ¸…ç†")
                total_items += 1
                
            elif op_name == 'clean_workspace':
                deleted = op_result.get('deleted_files', 0)
                if deleted > 0:
                    report_lines.append(f"âœ… å·¥ä½œåŒºæ¸…ç† - åˆ é™¤{deleted}æ–‡ä»¶")
                    total_success += 1
                else:
                    report_lines.append("âš ï¸  å·¥ä½œåŒºæ¸…ç† - æ— æ–‡ä»¶éœ€æ¸…ç†")
                total_items += 1
                
            elif op_name == 'clear_chat_history':
                deleted = op_result.get('deleted_files', 0)
                if deleted > 0:
                    report_lines.append(f"âœ… èŠå¤©å†å²æ¸…ç† - åˆ é™¤{deleted}æ–‡ä»¶")
                    total_success += 1
                else:
                    report_lines.append("âš ï¸  èŠå¤©å†å²æ¸…ç† - æ— å†å²éœ€æ¸…ç†")
                total_items += 1
                
            elif op_name == 'reinstall_plugin':
                installed = op_result.get('total_installed', 0)
                failed = op_result.get('total_failed', 0)
                if installed > 0:
                    report_lines.append(f"âœ… æ’ä»¶é‡å®‰è£… - æˆåŠŸ{installed}ä¸ª")
                    total_success += 1
                elif failed > 0:
                    report_lines.append(f"âŒ æ’ä»¶é‡å®‰è£… - å¤±è´¥{failed}ä¸ª")
                else:
                    report_lines.append("âš ï¸  æ’ä»¶é‡å®‰è£… - æ— æ“ä½œ")
                total_items += 1
        
        report_lines.append(f"\nğŸ“ˆ æ€»è®¡: {total_success}/{total_items} é¡¹æ“ä½œæˆåŠŸ")
        
        if operations_result.get('status') == 'success':
            report_lines.append("ğŸ‰ æ•´ä½“çŠ¶æ€: æ“ä½œå®Œæˆ")
        else:
            report_lines.append("âš ï¸  æ•´ä½“çŠ¶æ€: æœ‰é—®é¢˜éœ€è¦æ³¨æ„")
            
        report_lines.append("="*40)
        return "\n".join(report_lines)

    def auto_deep_clean(self, editor_type: str, max_retries: int = 3) -> Dict:
        """å…¨è‡ªåŠ¨æ·±åº¦æ¸…æ´— - å¤šé‡è¯•æœºåˆ¶ï¼Œç¡®ä¿æ— é—æ¼"""
        print("\n" + "ğŸš€" * 30)
        print("å…¨è‡ªåŠ¨æ·±åº¦æ¸…æ´—æ¨¡å¼")
        print("ğŸš€" * 30 + "\n")

        # è·å–ç¼–è¾‘å™¨è·¯å¾„
        editor_path = self.get_editor_path(editor_type)

        all_results = {
            'editor_type': editor_type,
            'rounds': [],
            'total_deleted_files': 0,
            'total_deleted_db_rows': 0,
            'verification_passed': False
        }

        for round_num in range(1, max_retries + 1):
            print(f"\n{'='*60}")
            print(f"ğŸ”„ ç¬¬ {round_num}/{max_retries} è½®æ¸…æ´—")
            print(f"{'='*60}\n")

            round_result = {
                'round': round_num,
                'scan_result': None,
                'clean_results': [],
                'verification': None
            }

            # æ­¥éª¤1: æ·±åº¦æ‰«æ
            print(f"ğŸ“ æ­¥éª¤1: æ·±åº¦æ‰«æ")
            scan_result = self.deep_scan_augment_data(editor_type)
            round_result['scan_result'] = scan_result

            if scan_result['total_found'] == 0:
                print(f"   âœ… æœªå‘ç°Augmentæ•°æ®ï¼Œæ¸…æ´—å®Œæˆï¼")
                round_result['verification'] = {'clean': True}
                all_results['rounds'].append(round_result)
                all_results['verification_passed'] = True
                break

            print(f"   ğŸ¯ å‘ç° {scan_result['total_found']} ä¸ªä½ç½®éœ€è¦æ¸…ç†")

            # æ­¥éª¤2: æ‰§è¡Œå¤šç§æ¸…ç†æ–¹æ¡ˆ
            print(f"\nğŸ“ æ­¥éª¤2: æ‰§è¡Œæ¸…ç†æ–¹æ¡ˆ")

            # æ–¹æ¡ˆA: æ¸…ç†globalStorageç›®å½•
            if scan_result['found_locations']['globalStorage_dirs']:
                print(f"   ğŸ”§ æ–¹æ¡ˆA: æ¸…ç†globalStorage ({len(scan_result['found_locations']['globalStorage_dirs'])}ä¸ª)")
                deleted = 0
                for dir_path in scan_result['found_locations']['globalStorage_dirs']:
                    try:
                        print(f"      ğŸ” æ£€æŸ¥: {dir_path}")
                        if not dir_path.exists():
                            print(f"      âš ï¸  è·¯å¾„ä¸å­˜åœ¨: {dir_path}")
                            continue

                        if self._is_dangerous_path(dir_path):
                            print(f"      âš ï¸  å±é™©è·¯å¾„ï¼Œè·³è¿‡: {dir_path}")
                            continue

                        file_count = len(list(dir_path.rglob("*")))
                        print(f"      ğŸ“Š åŒ…å« {file_count} ä¸ªæ–‡ä»¶")
                        shutil.rmtree(dir_path)
                        deleted += file_count
                        print(f"      âœ… åˆ é™¤: {dir_path.name} ({file_count}ä¸ªæ–‡ä»¶)")
                    except PermissionError as e:
                        print(f"      âŒ æƒé™ä¸è¶³: {e}")
                    except Exception as e:
                        print(f"      âŒ å¤±è´¥: {type(e).__name__}: {e}")

                round_result['clean_results'].append({'method': 'globalStorage', 'deleted': deleted})
                all_results['total_deleted_files'] += deleted
                print(f"      ğŸ“Š æ–¹æ¡ˆAæ€»è®¡åˆ é™¤: {deleted}ä¸ªæ–‡ä»¶")

            # æ–¹æ¡ˆB: æ¸…ç†workspaceStorageç›®å½•
            if scan_result['found_locations']['workspaceStorage_dirs']:
                print(f"   ğŸ”§ æ–¹æ¡ˆB: æ¸…ç†workspaceStorage ({len(scan_result['found_locations']['workspaceStorage_dirs'])}ä¸ª)")
                deleted = 0
                for dir_path in scan_result['found_locations']['workspaceStorage_dirs']:
                    try:
                        print(f"      ğŸ” æ£€æŸ¥: {dir_path.name[:30]}...")
                        if not dir_path.exists():
                            print(f"      âš ï¸  è·¯å¾„ä¸å­˜åœ¨")
                            continue

                        if self._is_dangerous_path(dir_path):
                            print(f"      âš ï¸  å±é™©è·¯å¾„ï¼Œè·³è¿‡")
                            continue

                        file_count = len(list(dir_path.rglob("*")))
                        print(f"      ğŸ“Š åŒ…å« {file_count} ä¸ªæ–‡ä»¶")
                        shutil.rmtree(dir_path)
                        deleted += file_count
                        print(f"      âœ… åˆ é™¤: {dir_path.name[:20]}... ({file_count}ä¸ªæ–‡ä»¶)")
                    except PermissionError as e:
                        print(f"      âŒ æƒé™ä¸è¶³: {e}")
                    except Exception as e:
                        print(f"      âŒ å¤±è´¥: {type(e).__name__}: {e}")

                round_result['clean_results'].append({'method': 'workspaceStorage', 'deleted': deleted})
                all_results['total_deleted_files'] += deleted
                print(f"      ğŸ“Š æ–¹æ¡ˆBæ€»è®¡åˆ é™¤: {deleted}ä¸ªæ–‡ä»¶")

            # æ–¹æ¡ˆC: æ¸…ç†æ•°æ®åº“
            if scan_result['found_locations']['database_files']:
                print(f"   ğŸ”§ æ–¹æ¡ˆC: æ¸…ç†æ•°æ®åº“ ({len(scan_result['found_locations']['database_files'])}ä¸ª)")
                deleted_rows = 0

                # ä»é…ç½®è·å–æ¸…ç†é”®
                cleanup_keys = self.config.get('database_cleanup_keys', {}).get('augment_specific', [
                    '%augment%', '%chat%', '%conversation%', '%message%',
                    '%dialog%', '%session%', '%history%', '%AugmentCode%',
                    '%augmentcode%', '%vscode-augment%', '%Fix with Augment%'
                ])

                for db_file, _ in scan_result['found_locations']['database_files']:
                    try:
                        conn = sqlite3.connect(db_file)
                        cursor = conn.cursor()

                        for key_pattern in cleanup_keys:
                            cursor.execute("DELETE FROM ItemTable WHERE key LIKE ?", (key_pattern,))
                            deleted_rows += cursor.rowcount

                        conn.commit()
                        conn.close()
                        print(f"      âœ… æ¸…ç†: {Path(db_file).parent.name[:20]}... ({deleted_rows}è¡Œ)")
                    except Exception as e:
                        print(f"      âŒ å¤±è´¥: {e}")

                round_result['clean_results'].append({'method': 'database', 'deleted': deleted_rows})
                all_results['total_deleted_db_rows'] += deleted_rows

            # æ–¹æ¡ˆD: æ¸…ç†å…¶ä»–æ–‡ä»¶
            if scan_result['found_locations']['other_files']:
                print(f"   ğŸ”§ æ–¹æ¡ˆD: æ¸…ç†å…¶ä»–æ–‡ä»¶ ({len(scan_result['found_locations']['other_files'])}ä¸ª)")
                deleted = 0
                for file_path in scan_result['found_locations']['other_files']:
                    try:
                        print(f"      ğŸ” æ£€æŸ¥: {file_path.name[:50]}...")
                        if not file_path.exists():
                            print(f"      âš ï¸  è·¯å¾„ä¸å­˜åœ¨")
                            continue

                        if self._is_dangerous_path(file_path):
                            print(f"      âš ï¸  å±é™©è·¯å¾„ï¼Œè·³è¿‡")
                            continue

                        if file_path.is_file():
                            file_path.unlink()
                            deleted += 1
                            print(f"      âœ… åˆ é™¤æ–‡ä»¶: {file_path.name[:40]}...")
                        elif file_path.is_dir():
                            file_count = len(list(file_path.rglob("*")))
                            shutil.rmtree(file_path)
                            deleted += file_count
                            print(f"      âœ… åˆ é™¤ç›®å½•: {file_path.name[:40]}... ({file_count}ä¸ªæ–‡ä»¶)")
                    except PermissionError as e:
                        print(f"      âŒ æƒé™ä¸è¶³: {e}")
                    except Exception as e:
                        print(f"      âŒ å¤±è´¥: {type(e).__name__}: {e}")

                round_result['clean_results'].append({'method': 'other_files', 'deleted': deleted})
                all_results['total_deleted_files'] += deleted
                print(f"      ğŸ“Š æ–¹æ¡ˆDæ€»è®¡åˆ é™¤: {deleted}ä¸ªæ–‡ä»¶")

            # æ­¥éª¤3: éªŒè¯æ¸…ç†æ•ˆæœ
            print(f"\nğŸ“ æ­¥éª¤3: éªŒè¯æ¸…ç†æ•ˆæœ")
            time.sleep(2)  # ç­‰å¾…æ–‡ä»¶ç³»ç»ŸåŒæ­¥

            verify_scan = self.deep_scan_augment_data(editor_type)
            round_result['verification'] = verify_scan

            if verify_scan['total_found'] == 0:
                print(f"   âœ… éªŒè¯é€šè¿‡ï¼æ‰€æœ‰Augmentæ•°æ®å·²æ¸…é™¤")
                all_results['verification_passed'] = True
                all_results['rounds'].append(round_result)
                break
            else:
                print(f"   âš ï¸  ä»æœ‰ {verify_scan['total_found']} ä¸ªä½ç½®æ®‹ç•™ï¼Œç»§ç»­ä¸‹ä¸€è½®...")
                all_results['rounds'].append(round_result)

        # æœ€ç»ˆæŠ¥å‘Š
        print(f"\n{'='*60}")
        print(f"ğŸ“Š å…¨è‡ªåŠ¨æ·±åº¦æ¸…æ´—å®ŒæˆæŠ¥å‘Š")
        print(f"{'='*60}")
        print(f"   æ‰§è¡Œè½®æ•°: {len(all_results['rounds'])}/{max_retries}")
        print(f"   åˆ é™¤æ–‡ä»¶: {all_results['total_deleted_files']}ä¸ª")
        print(f"   åˆ é™¤æ•°æ®åº“è®°å½•: {all_results['total_deleted_db_rows']}è¡Œ")
        print(f"   éªŒè¯çŠ¶æ€: {'âœ… é€šè¿‡' if all_results['verification_passed'] else 'âš ï¸  æœªå®Œå…¨æ¸…é™¤'}")

        if not all_results['verification_passed']:
            print(f"\nâš ï¸  è­¦å‘Š: ç»è¿‡{max_retries}è½®æ¸…æ´—ä»æœ‰æ®‹ç•™æ•°æ®")
            print(f"   å»ºè®®: 1) æ£€æŸ¥æ–‡ä»¶æƒé™ 2) ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œ 3) æ‰‹åŠ¨æ£€æŸ¥æ®‹ç•™ä½ç½®")

        return all_results

def main():
    """ä¸»å‡½æ•°"""
    manager = TelemetryManager()
    
    print("=== VS Code/Cursor/VSCodium é¥æµ‹ç®¡ç†å™¨ ===")
    
    # è·å–ç³»ç»Ÿä¿¡æ¯
    system_info = manager.get_system_info()
    print(f"ç³»ç»Ÿä¿¡æ¯: {json.dumps(system_info, indent=2, ensure_ascii=False)}")
    
    if not system_info['available_editors']:
        print("æœªæ£€æµ‹åˆ°æ”¯æŒçš„ç¼–è¾‘å™¨")
        return
    
    # æ˜¾ç¤ºå¯ç”¨ç¼–è¾‘å™¨
    print("\nå¯ç”¨çš„ç¼–è¾‘å™¨:")
    for i, editor in enumerate(system_info['available_editors']):
        print(f"{i+1}. {editor['name']} ({editor['type']})")
    
    # é€‰æ‹©ç¼–è¾‘å™¨
    try:
        choice = int(input("\nè¯·é€‰æ‹©ç¼–è¾‘å™¨ (è¾“å…¥æ•°å­—): ")) - 1
        if choice < 0 or choice >= len(system_info['available_editors']):
            print("æ— æ•ˆé€‰æ‹©")
            return
        
        selected_editor = system_info['available_editors'][choice]
        editor_type = selected_editor['type']
        
        print(f"\nå·²é€‰æ‹©: {selected_editor['name']}")
        
        # æ˜¾ç¤ºæ“ä½œé€‰é¡¹
        operations = manager.get_supported_operations()
        print("\næ”¯æŒçš„æ“ä½œ:")
        for i, op in enumerate(operations):
            print(f"{i+1}. {op}")
        print(f"{len(operations)+1}. æ‰§è¡Œæ‰€æœ‰æ“ä½œ (ç®€åŒ–æŠ¥å‘Š)")
        print(f"{len(operations)+2}. æ‰§è¡Œå®Œæ•´æ“ä½œåºåˆ— (è¯¦ç»†æŠ¥å‘Š)")
        print(f"{len(operations)+3}. ğŸš€ å…¨è‡ªåŠ¨æ·±åº¦æ¸…æ´—æ¨¡å¼ (æ¨è)")

        # é€‰æ‹©æ“ä½œ
        op_choice = int(input("\nè¯·é€‰æ‹©æ“ä½œ (è¾“å…¥æ•°å­—): "))

        if op_choice == len(operations) + 1:
            # æ‰§è¡Œæ‰€æœ‰æ“ä½œ
            result = manager.run_all_operations(editor_type)
            print(f"\næ‰§è¡Œç»“æœ:\n{json.dumps(result, indent=2, ensure_ascii=False)}")

            # ç”Ÿæˆç®€åŒ–æŠ¥å‘Š
            print(manager.generate_simple_report(result))

        elif op_choice == len(operations) + 2:
            # æ‰§è¡Œå®Œæ•´æ“ä½œåºåˆ—ï¼ˆåŒ…å«æŠ¥å‘Šï¼‰
            result = manager.run_all_operations_command(editor_type)
            # æŠ¥å‘Šå·²åœ¨å‡½æ•°å†…æ‰“å°

        elif op_choice == len(operations) + 3:
            # ğŸš€ å…¨è‡ªåŠ¨æ·±åº¦æ¸…æ´—æ¨¡å¼
            print("\n" + "ğŸš€" * 30)
            print("å¯åŠ¨å…¨è‡ªåŠ¨æ·±åº¦æ¸…æ´—æ¨¡å¼")
            print("ğŸš€" * 30)
            print("\nâš ï¸  æ³¨æ„äº‹é¡¹:")
            print("   1. æ­¤æ¨¡å¼å°†æ‰§è¡Œå¤šè½®æ·±åº¦æ‰«æå’Œæ¸…ç†")
            print("   2. ä¼šè‡ªåŠ¨é‡è¯•ç›´åˆ°å®Œå…¨æ¸…é™¤æˆ–è¾¾åˆ°æœ€å¤§è½®æ•°")
            print("   3. å»ºè®®å…ˆå…³é—­æ‰€æœ‰VS Codeçª—å£")
            print("   4. å»ºè®®ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œ")

            confirm = input("\næ˜¯å¦ç»§ç»­? (y/n): ").lower()
            if confirm != 'y':
                print("å·²å–æ¶ˆæ“ä½œ")
                return

            # æ­¥éª¤1: å¼ºåˆ¶ç»“æŸè¿›ç¨‹
            print("\nğŸ“ æ­¥éª¤1: å¼ºåˆ¶ç»“æŸç¼–è¾‘å™¨è¿›ç¨‹")
            kill_result = manager.kill_editor_processes_command(editor_type)
            if kill_result['status'] == 'success':
                print(f"   âœ… æˆåŠŸç»ˆæ­¢ {kill_result.get('total_killed', 0)} ä¸ªè¿›ç¨‹")
            else:
                print(f"   âš ï¸  è¿›ç¨‹ç»ˆæ­¢çŠ¶æ€: {kill_result['status']}")

            # æ­¥éª¤2: ä¿®æ”¹é¥æµ‹ID
            print("\nğŸ“ æ­¥éª¤2: ä¿®æ”¹é¥æµ‹ID")
            try:
                telemetry_result = manager.modify_telemetry_ids(editor_type)
                print(f"   âœ… é¥æµ‹IDå·²ä¿®æ”¹")
                print(f"   æ–°machineId: {telemetry_result['new_machine_id'][:8]}...")
            except Exception as e:
                print(f"   âš ï¸  é¥æµ‹IDä¿®æ”¹å¤±è´¥: {e}")

            # æ­¥éª¤3: å…¨è‡ªåŠ¨æ·±åº¦æ¸…æ´—
            print("\nğŸ“ æ­¥éª¤3: æ‰§è¡Œå…¨è‡ªåŠ¨æ·±åº¦æ¸…æ´—")
            max_retries = 3
            retry_input = input(f"   æœ€å¤§é‡è¯•è½®æ•° (é»˜è®¤{max_retries}): ").strip()
            if retry_input.isdigit():
                max_retries = int(retry_input)

            clean_result = manager.auto_deep_clean(editor_type, max_retries=max_retries)

            # æ­¥éª¤4: æœ€ç»ˆéªŒè¯
            print("\nğŸ“ æ­¥éª¤4: æœ€ç»ˆéªŒè¯")
            final_scan = manager.deep_scan_augment_data(editor_type)

            if final_scan['total_found'] == 0:
                print("   âœ…âœ…âœ… å®Œç¾ï¼æ‰€æœ‰Augmentæ•°æ®å·²å½»åº•æ¸…é™¤ï¼")
            else:
                print(f"   âš ï¸  ä»æœ‰ {final_scan['total_found']} ä¸ªä½ç½®æ®‹ç•™")
                print("   æ®‹ç•™ä½ç½®è¯¦æƒ…:")
                for key, items in final_scan['found_locations'].items():
                    if items:
                        print(f"      - {key}: {len(items)}ä¸ª")

            # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            print("\n" + "="*60)
            print("ğŸ“Š å…¨è‡ªåŠ¨æ·±åº¦æ¸…æ´—æœ€ç»ˆæŠ¥å‘Š")
            print("="*60)
            print(f"   æ‰§è¡Œè½®æ•°: {len(clean_result['rounds'])}/{max_retries}")
            print(f"   åˆ é™¤æ–‡ä»¶æ€»æ•°: {clean_result['total_deleted_files']}")
            print(f"   åˆ é™¤æ•°æ®åº“è®°å½•: {clean_result['total_deleted_db_rows']}")
            print(f"   æœ€ç»ˆéªŒè¯: {'âœ… é€šè¿‡' if final_scan['total_found'] == 0 else 'âš ï¸  æœ‰æ®‹ç•™'}")
            print("="*60)

        elif 1 <= op_choice <= len(operations):
            # æ‰§è¡Œå•ä¸ªæ“ä½œ
            operation = operations[op_choice - 1]
            method = getattr(manager, operation)

            if operation == 'kill_editor_processes':
                result = method(editor_type)
                print(f"\næ“ä½œç»“æœ: {result}")
            else:
                result = method(editor_type)
                print(f"\næ“ä½œç»“æœ:\n{json.dumps(result, indent=2, ensure_ascii=False)}")
        else:
            print("æ— æ•ˆé€‰æ‹©")

    except KeyboardInterrupt:
        print("\n\næ“ä½œå·²å–æ¶ˆ")
    except Exception as e:
        print(f"\næ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()